{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ee0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/darioka/impactdeal-2022.git\n",
    "#%cd impactdeal-2022\n",
    "#!pip install -r requirements.txt\n",
    "#!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0781279",
   "metadata": {},
   "source": [
    "# Decision Trees - EPC Rating\n",
    "\n",
    "In this notebook you will fit a `DecisionTreeClassifier` on the EPC rating dataset. You will experience for yourself what it means to work with real world data!\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "As we did for the exploration, let's load the dataset `known_epc_ratings.csv.gz`. If you remember, there is a column with datetime values. It could be useful to convert it to the correct datetime data type during loading. Take a look at `parse_dates` and `infer_datetime_format` of the `pandas`'s documentation about the `read_csv` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4faf281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "\n",
    "# ...\n",
    "\n",
    "# raw_df ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de62d63c",
   "metadata": {},
   "source": [
    "## The problem\n",
    "\n",
    "We remember from the exploration here we don't have a binary classification problem, but a **multiclass classification**. Fortunately, there will be no difference in how we train a `DecisionTreeClassifier`. There will be some differences though in the way we interpret the performance metrics.\n",
    "\n",
    "Let's now discuss more deeply about the EPC rating dataset. There is small discrepancy between what we want to do, that is to predict the EPC rating *for each property*, and what the dataset is: a collection of data *for each EPC assessment*. In other words, **the dataset may contain multiple EPC ratings for each property**. There are several reasons why we must take that into account:\n",
    "1. Older EPC ratings may have been updated and could contain incorrect data.\n",
    "2. If a property has two EPC ratings, say A and B, what should the model output for that property? A or B?\n",
    "3. If a property has two EPC ratings, when we split the data, one of the sample could be in the training set and the other in the test set. This may lead to an overestimation of the performance of a model on the test set.\n",
    "\n",
    "In the following cells, show that there are multiple EPC ratings for the same `BUILDING_REFERENCE_NUMBER`. Then create a new dataframe with only the most recent assessments for each property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167233df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "\n",
    "# ...\n",
    "\n",
    "# df ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48ad65",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "During exploration we saw that the dataset has some issues with data quality. Some cleaning functions have been provided for your convenience. You can find them in the `cleaning` module of the package `impactdeal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27232d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from impactdeal.config.column_names import TARGET, NUMERICAL, CATEGORICAL\n",
    "from impactdeal import cleaning\n",
    "\n",
    "# all missing values in the categorical columns will be replaced with np.nan\n",
    "df = cleaning.normalize_missing(df, CATEGORICAL)\n",
    "\n",
    "# specific cleaning steps for some of the features\n",
    "df = cleaning.clean_age_band(df)\n",
    "df = cleaning.clean_floor_level(df)\n",
    "df = cleaning.clean_mainheat(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08fc8a",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Here we start we the preprocessing steps that will lead us to model training.\n",
    "\n",
    "### Train-test split\n",
    "\n",
    "First of all, let's define `X` as a dataframe with the features we want to use, namely `NUMERICAL` and `CATEGORICAL`, and `y` as the series with the `TARGET`.\n",
    "\n",
    "Then split `X` and `y` in train (70%) and test (30%), stratifying on `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c77f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "\n",
    "# ...\n",
    "\n",
    "# X = \n",
    "# y = \n",
    "\n",
    "# X_train, X_test, y_train, y_test ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21961d",
   "metadata": {},
   "source": [
    "### Dropping columns\n",
    "\n",
    "As we saw during exploration, some of the features we have hardly convey information. This is the case with columns that mostly contain missing data. Additionally, we noticed that there are multiple variables with information about lighting in the property, that they are correlated and some of them have many missing values.\n",
    "\n",
    "For simplicity, let's also discard all textual columns (the ones whose name ends with `DESCRIPTION`). Being free text, if we treat them as simple categories we could have a huge amount of classes. This is not helpful for any model. There are are methods to treat text, that we will see in future modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf7b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "\n",
    "# ...\n",
    "\n",
    "# numerical_cols = [...]\n",
    "# categorical_cols = [...]\n",
    "\n",
    "# X_train = \n",
    "# X_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec58fc",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "In this dataset, missing values can be found both in numerical and categorical columns. We saw that a good way to encode missing values for categorical columns is to treat them as another category. For numerical values instead our solution will be [imputation](https://en.wikipedia.org/wiki/Imputation_(statistics)).\n",
    "\n",
    "A common imputation method is mean imputation, where one replaces missing data in a column with the mean value of that column. This is an assumption, of course, and sometimes better assumptions could be made trying to understand the data collection process.\n",
    "\n",
    "In our case, for example, if `MULTI_GLAZE_PROPORTION` is null it seems reasonable to think that the property has no multiple glazing, which would be equivalent to set `MULTI_GLAZE_PROPORTION=0`. This could be a more conservative assumption compared to the mean.\n",
    "\n",
    "In the following cells, decide for which features it would be better to use a constant value imputation and for which ones a mean imputation. Then apply the transformations using `scikit-lean` [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "\n",
    "# ...\n",
    "\n",
    "# zero_imputed_cols = [...]\n",
    "# mean_imputed_cols = [...]\n",
    "\n",
    "# ...\n",
    "\n",
    "# X_train[zero_imputed_cols] = \n",
    "# X_train[mean_imputed_cols] = \n",
    "# X_test[zero_imputed_cols] = \n",
    "# X_test[mean_imputed_cols] = \n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a7166",
   "metadata": {},
   "source": [
    "### Categorical encoding\n",
    "\n",
    "Now we will encode categorical variables. However...\n",
    "\n",
    "One problem with categorical variables in real world datasets is rare classes, for several reasons:\n",
    "1. Why are there so few samples with those classes? Instead of valid classes, they could be just errors in the data collection process.\n",
    "2. If only few samples belongs to a category, every machine learning model will struggle to learn anything from them. Having many rare classes is never beneficial for models.\n",
    "3. Having many rare classes does not help interpretation.\n",
    "4. If there are very few examples with a certain class, they might end up in just one of the train o test dataset.\n",
    "\n",
    "For these reasons, before the `OrdinalEncoder` we will add one more preprocessing step that converts rare classes to another constant value, for example `\"other\"` or `np.nan`.\n",
    "\n",
    "Read the docstring of the object `impactdeal.CategoryReducer`, then use it followed by `OrdinalEncoder` to encode all categorical columns in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e64dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "\n",
    "# ...\n",
    "\n",
    "# X_train[categorical_cols] = \n",
    "# X_test[categorical_cols] = \n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26122eb",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Finally, we can now train our decision tree. In the following cell, fit a `DecisionTreeClassifier`, then score the model on the test set the visualize the predictions with a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
