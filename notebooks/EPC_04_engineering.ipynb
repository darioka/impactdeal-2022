{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1ee0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/darioka/impactdeal-2022.git\n",
    "#%cd impactdeal-2022\n",
    "#!pip install -r requirements.txt\n",
    "#!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0d684",
   "metadata": {},
   "source": [
    "# Feature Engineering - EPC Rating\n",
    "\n",
    "In this notebook we are going to work on the dataset in order to provide more information to the machine learning model we want to train.\n",
    "\n",
    "This process of creating, selecting, extracting, transforming variables is known as **feature engineering** in machine learning. Together with cleaning, this is the step where data scientist spend most of their times, as the quality of data and features are the most impactful factors for the performances of a model.\n",
    "\n",
    "In the following, we will focus on three aspects of the EPC rating dataset:\n",
    "1. a better solution for missing values in the number of rooms,\n",
    "2. the creation of new variables,\n",
    "3. feature extraction from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec13c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darioka/anaconda3/envs/impactdeal/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from impactdeal.config.column_names import TARGET\n",
    "from impactdeal.cleaning import Cleaner\n",
    "\n",
    "df = pd.read_csv(\"data/known_epc_ratings.csv.gz\", parse_dates=[\"INSPECTION_DATE\"], infer_datetime_format=True)\n",
    "df = df.sort_values([\"BUILDING_REFERENCE_NUMBER\", \"INSPECTION_DATE\"]).drop_duplicates(subset=\"BUILDING_REFERENCE_NUMBER\", keep=\"last\")\n",
    "\n",
    "y = df.pop(TARGET)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "cleaner = Cleaner(text_features=True)\n",
    "X_train = cleaner.fit_transform(X_train)\n",
    "X_test = cleaner.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876ebef",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "We saw that `NUMBER_HABITABLE_ROOMS` and `NUMBER_HEATED_ROOMS` have many missing values. But while a replacement with the mean for `FLOOR_HEIGHT` was a reasonable solution, the number of rooms strongly depends on other factors, as for example `TOTAL_FLOOR_AREA`.\n",
    "\n",
    "We will now show how a **linear regression** between floor area and number of rooms could be a better tool to substitute missing data. In practice, we will use another machine learning model to predict `NUMBER_HABITABLE_ROOMS` or `NUMBER_HEATED_ROOMS` given the value of `TOTAL_FLOOR_AREA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d60f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reg_x_cols = [\"TOTAL_FLOOR_AREA\"]\n",
    "reg_y_cols = [\"NUMBER_HABITABLE_ROOMS\", \"NUMBER_HEATED_ROOMS\"]\n",
    "\n",
    "# the dataset for regression is the part of the train dataset where there are no missing values\n",
    "reg_dataset = X_train[reg_x_cols + reg_y_cols].dropna()\n",
    "reg_x = reg_dataset[reg_x_cols]\n",
    "reg_y_habitable = reg_dataset[\"NUMBER_HABITABLE_ROOMS\"]\n",
    "reg_y_heated = reg_dataset[\"NUMBER_HEATED_ROOMS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1960cd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute difference btw actual and predicted #rooms\n",
      "-----------------------------------------------------------\n",
      "1.27 rooms  (BASELINE)\n",
      "0.80 rooms  (LINEAR REGRESSION)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# consider the act of replacing with the mean as a model\n",
    "# that for every x always predict the same value i.e. the mean of y\n",
    "baseline_model = DummyRegressor(strategy=\"mean\")\n",
    "baseline_model.fit(reg_x, reg_y_habitable)\n",
    "\n",
    "# use a simple linear regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(reg_x, reg_y_habitable)\n",
    "\n",
    "# measure performances via cross validation\n",
    "# with mean absolute error = avg(|y_true - y_pred|)\n",
    "baseline_score = -cross_validate(\n",
    "    baseline_model, reg_x, reg_y_habitable, cv=10,\n",
    "    scoring=\"neg_mean_absolute_error\"\n",
    ")[\"test_score\"].mean()\n",
    "\n",
    "linear_score = -cross_validate(\n",
    "    linear_model, reg_x, reg_y_habitable, cv=10,\n",
    "    scoring=\"neg_mean_absolute_error\"\n",
    ")[\"test_score\"].mean()\n",
    "\n",
    "print(\"Mean absolute difference btw actual and predicted #rooms\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print(f\"{baseline_score:.2f} rooms  (BASELINE)\")\n",
    "print(f\"{linear_score:.2f} rooms  (LINEAR REGRESSION)\")\n",
    "\n",
    "plot = sns.jointplot(\n",
    "    data=reg_dataset.sample(500, random_state=42),\n",
    "    x=\"TOTAL_FLOOR_AREA\", y=\"NUMBER_HABITABLE_ROOMS\",\n",
    "    kind=\"reg\", height=8\n",
    ")\n",
    "plot.ax_joint.axhline(y=reg_y_habitable.mean(), linestyle=\"--\", color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873f73a",
   "metadata": {},
   "source": [
    "Now, it is time to use the new imputing strategy to replace missing values.\n",
    "\n",
    "The class `impactdeal.preprocessing.RoomsImputer` implements a transformer that fits linear models on `TOTAL_FLOOR_AREA` to predict `NUMBER_HABITABLE_ROOMS` and `NUMBER_HEATED_ROOMS`, and it can be used as a preprocessing step (actually, the linear model therein has some more tricks...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f89aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from impactdeal.preprocessing import RoomsImputer\n",
    "\n",
    "imputer = RoomsImputer()\n",
    "imputer.fit(X_train)\n",
    "\n",
    "X_train[imputer.feature_names_out_] = imputer.transform(X_train)\n",
    "X_test[imputer.feature_names_out_] = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c009712",
   "metadata": {},
   "source": [
    "Finally, we keep the same strategy for the other numerical missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f9d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "zero_imputed_cols = [\n",
    "    \"MULTI_GLAZE_PROPORTION\",\n",
    "    \"EXTENSION_COUNT\",\n",
    "    \"LOW_ENERGY_LIGHTING\",\n",
    "    \"NUMBER_OPEN_FIREPLACES\",\n",
    "    \"WIND_TURBINE_COUNT\"\n",
    "]\n",
    "mean_imputed_cols = [\"FLOOR_HEIGHT\"]\n",
    "\n",
    "zero_imputer = SimpleImputer(strategy=\"constant\", fill_value=0)\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "X_train[zero_imputed_cols] = zero_imputer.fit_transform(X_train[zero_imputed_cols])\n",
    "X_test[zero_imputed_cols] = zero_imputer.transform(X_test[zero_imputed_cols])\n",
    "X_train[mean_imputed_cols] = zero_imputer.fit_transform(X_train[mean_imputed_cols])\n",
    "X_test[mean_imputed_cols] = zero_imputer.transform(X_test[mean_imputed_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3a83de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TOTAL_FLOOR_AREA          0\n",
       "MULTI_GLAZE_PROPORTION    0\n",
       "EXTENSION_COUNT           0\n",
       "NUMBER_HABITABLE_ROOMS    0\n",
       "NUMBER_HEATED_ROOMS       0\n",
       "LOW_ENERGY_LIGHTING       0\n",
       "NUMBER_OPEN_FIREPLACES    0\n",
       "WIND_TURBINE_COUNT        0\n",
       "FLOOR_HEIGHT              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.select_dtypes(float).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf140222",
   "metadata": {},
   "source": [
    "## New features\n",
    "\n",
    "This is where our creativity and domain knowledge can be put into practice!\n",
    "\n",
    "**Can you think of some variables we could add?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66291bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some new features\n",
    "\n",
    "\n",
    "X_train[\"floor_volume\"] = X_train[\"TOTAL_FLOOR_AREA\"] * X_train[\"FLOOR_HEIGHT\"]\n",
    "X_test[\"floor_volume\"] = X_test[\"TOTAL_FLOOR_AREA\"] * X_test[\"FLOOR_HEIGHT\"]\n",
    "\n",
    "X_train[\"avg_room_area\"] = (X_train[\"TOTAL_FLOOR_AREA\"] / X_train[\"NUMBER_HABITABLE_ROOMS\"]).replace([np.nan, np.inf, -np.inf], 0)\n",
    "X_test[\"avg_room_area\"] = (X_test[\"TOTAL_FLOOR_AREA\"] / X_test[\"NUMBER_HABITABLE_ROOMS\"]).replace([np.nan, np.inf, -np.inf], 0)\n",
    "\n",
    "X_train[\"ratio_heated_rooms\"] = X_train[\"NUMBER_HEATED_ROOMS\"] / X_train[\"NUMBER_HABITABLE_ROOMS\"]\n",
    "X_test[\"ratio_heated_rooms\"] = X_test[\"NUMBER_HEATED_ROOMS\"] / X_test[\"NUMBER_HABITABLE_ROOMS\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282f2c1",
   "metadata": {},
   "source": [
    "## Text\n",
    "\n",
    "So far we neglected possible information coming from the columns whose name ends with `DESCRIPTION`. It was a deliberate choice, because those columns seem to contain free text, which is more difficult to handle. In fact, it cannot be treated as a category, as the unique values would be too many, but there are ways to extract useful features.\n",
    "\n",
    "First of all, let's take a look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f04df436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209623                       From main system\n",
      "301201           Electric immersion, off-peak\n",
      "425412    Electric immersion, standard tariff\n",
      "Name: HOTWATER_DESCRIPTION, dtype: object\n",
      "\n",
      "209623    Solid, no insulation (assumed)\n",
      "301201            (other premises below)\n",
      "425412          (another dwelling below)\n",
      "Name: FLOOR_DESCRIPTION, dtype: object\n",
      "\n",
      "209623    Fully double glazed\n",
      "301201    Fully double glazed\n",
      "425412    Fully double glazed\n",
      "Name: WINDOWS_DESCRIPTION, dtype: object\n",
      "\n",
      "209623                    Cavity wall, filled cavity\n",
      "301201    Cavity wall, as built, insulated (assumed)\n",
      "425412    Cavity wall, as built, insulated (assumed)\n",
      "Name: WALLS_DESCRIPTION, dtype: object\n",
      "\n",
      "209623                      None\n",
      "301201    Room heaters, electric\n",
      "425412                      None\n",
      "Name: SECONDHEAT_DESCRIPTION, dtype: object\n",
      "\n",
      "209623    Pitched, 100 mm loft insulation\n",
      "301201           (another dwelling above)\n",
      "425412           (another dwelling above)\n",
      "Name: ROOF_DESCRIPTION, dtype: object\n",
      "\n",
      "209623    Boiler and radiators, mains gas\n",
      "301201           Electric storage heaters\n",
      "425412     Boiler and radiators, electric\n",
      "Name: MAINHEAT_DESCRIPTION, dtype: object\n",
      "\n",
      "209623          Programmer and room thermostat\n",
      "301201                   Manual charge control\n",
      "425412    Programmer, room thermostat and TRVs\n",
      "Name: MAINHEATCONT_DESCRIPTION, dtype: object\n",
      "\n",
      "209623       Low energy lighting in all fixed outlets\n",
      "301201    Low energy lighting in 40% of fixed outlets\n",
      "425412    Low energy lighting in 56% of fixed outlets\n",
      "Name: LIGHTING_DESCRIPTION, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_text = X_train.sample(3, random_state=42)\n",
    "for c in example_text.columns:\n",
    "    if c.endswith(\"DESCRIPTION\"):\n",
    "        print(example_text[c])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff306177",
   "metadata": {},
   "source": [
    "Based on the few lines we read, it is free text, but it seems somewhat structured. Text is short and similar expressions appear multiple times. If we were experts, probably we would understand the information contained in the text by looking at **keywords**. This suggests that if we could encode the text in a way that highlights the presence or not of a certain word, maybe a dowstream algorithm could be able to find correlations between some words and the actual target.\n",
    "\n",
    "This procedure of encoding text in an array of numbers representing words is standard in machine learning. The workflow is the following:\n",
    "1. preprocess text (remove punctuation, split words, ...),\n",
    "2. build a vocabulary,\n",
    "3. transform text into a vector of 0-1 indicating the presence of each word.\n",
    "\n",
    "For example:\n",
    "```\n",
    "Hello world!    -->  [\"hello\", \"world\"]\n",
    "Hello, Dario    -->  [\"hello\", \"dario\"]\n",
    "\n",
    "vocabulary = [\"hello\", \"world\", \"dario\"]\n",
    "                 \n",
    "Hello world!    ==>  [1, 1, 0]\n",
    "Hello, Dario    ==>  [1, 0, 1]\n",
    "```\n",
    "\n",
    "This representation is similar to [one-hot encoding](https://en.wikipedia.org/wiki/One-hot).\n",
    "\n",
    "In a text, we could also have the same word multiple times. In that case:\n",
    "\n",
    "```\n",
    "Hello hello     ==>  [2, 0, 0]\n",
    "```\n",
    "\n",
    "Instead of counts, we could also use **term frequency** i.e. the number of times a word occur divided by the total number of words in the text. This is one of the easiest way to encode text as a numeric vector to make it ready for a machine learning model. Another very well know strategy is [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), where each word in a text sample is encoded with its term frequency, divided by (the logarithm of) the frequency of the same words in all text samples.\n",
    "\n",
    "In our case, we will use the \"count\" vectorization implemented in the `scikit-learn` [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4ac26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_cols = [x for x in X_train if x.endswith(\"DESCRIPTION\")]\n",
    "vectorizers = {}\n",
    "\n",
    "# for each text column\n",
    "# create and fit a sklearn vectorizer\n",
    "# replacing missing data with empty strings\n",
    "for c in text_cols:\n",
    "    vectorizers[c] = CountVectorizer(lowercase=True).fit(X_train[c].fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce59cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 words in the vocabularies of text columns\n",
      "--------------------------------------------\n",
      "\n",
      "HOTWATER_DESCRIPTION\n",
      "['from', 'main', 'system', 'electric', 'immersion', 'off', 'peak', 'instantaneous', 'at', 'point', 'of', 'use', 'standard', 'tariff', 'no', 'cylinder', 'thermostat', 'community', 'scheme', 'present']\n",
      "\n",
      "FLOOR_DESCRIPTION\n",
      "['suspended', 'no', 'insulation', 'assumed', 'other', 'premises', 'below', 'solid', 'limited', 'average', 'thermal', 'transmittance', '14', 'm²k', '22', 'insulated', 'another', 'dwelling', '15', 'to']\n",
      "\n",
      "WINDOWS_DESCRIPTION\n",
      "['partial', 'double', 'glazing', 'fully', 'glazed', 'full', 'secondary', 'high', 'performance', 'single', 'mostly', 'glazeddouble', 'some', 'gwydrau', 'dwbl', 'llawn', 'multiple', 'triple', 'throughout', 'ffenestri']\n",
      "\n",
      "WALLS_DESCRIPTION\n",
      "['solid', 'brick', 'as', 'built', 'no', 'insulation', 'assumed', 'cavity', 'wall', 'filled', 'partial', 'insulated', 'average', 'thermal', 'transmittance', '68', 'm²k', '19', 'timber', 'frame']\n",
      "\n",
      "SECONDHEAT_DESCRIPTION\n",
      "['room', 'heaters', 'mains', 'gas', 'none', 'electric', 'portable', 'assumed', 'dual', 'fuel', 'mineral', 'and', 'wood', 'smokeless', 'logs', 'dim', 'coal', 'lpg', 'anthracite', 'chips']\n",
      "\n",
      "ROOF_DESCRIPTION\n",
      "['pitched', '25', 'mm', 'loft', 'insulation', 'insulated', 'at', 'rafters', 'flat', 'limited', 'assumed', '200', 'another', 'dwelling', 'above', 'other', 'premises', '250mm', 'no', '300']\n",
      "\n",
      "MAINHEAT_DESCRIPTION\n",
      "['boiler', 'and', 'radiators', 'mains', 'gas', 'electric', 'storage', 'heaters', 'room', 'community', 'scheme', 'no', 'system', 'present', 'assumed', 'underfloor', 'heating', 'portable', 'for', 'most']\n",
      "\n",
      "MAINHEATCONT_DESCRIPTION\n",
      "['programmer', 'and', 'room', 'thermostat', 'trvs', 'bypass', 'automatic', 'charge', 'control', 'no', 'thermostatic', 'of', 'temperature', 'thermostats', 'time', 'zone', 'appliance', 'manual', 'charging', 'system']\n",
      "\n",
      "LIGHTING_DESCRIPTION\n",
      "['low', 'energy', 'lighting', 'in', '89', 'of', 'fixed', 'outlets', 'no', '75', 'all', '50', '43', '55', '25', '23', '67', '18', '38', '83']\n"
     ]
    }
   ],
   "source": [
    "print(\"20 words in the vocabularies of text columns\")\n",
    "print(\"--------------------------------------------\")\n",
    "for col, v in vectorizers.items():\n",
    "    print()\n",
    "    print(col)\n",
    "    print(list(v.vocabulary_.keys())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8890b",
   "metadata": {},
   "source": [
    "Do all those words provide useful information? Maybe not...\n",
    "* **Prepositions** and **articles** are not very useful. We could use a list of **stop words** and avoid to keep them in the vocabulary.\n",
    "* Some of the vocabularies are full of numbers: they may be useful of course, they are not very representative of the meaning. Moreover they will greatly increase the dimension of the one-hot encoded vector. In this case, we could think of **replacing every number with a single new token**, like `numbertoken` (or any other word that wouldn't be confused with something else).\n",
    "* Some words could be very rare and be present only in a few documents. We could set a **lower limit to term frequency**, so that words are allowed into the vocabulary only if there are more than 10 occurrencies, for example.\n",
    "\n",
    "When working with text, we often need to search, match, replace letters or words inside a bigger piece of text. [Regular expressions](https://en.wikipedia.org/wiki/Regular_expression) help us with that, providing a \"language\" for pattern matching. They have a very long history and are not specific to python. You can find [many](https://docs.python.org/3/howto/regex.html) [tutorials](https://www.w3schools.com/python/python_regex.asp) on the internet, and also [online tools](https://regex101.com/) to test.\n",
    "\n",
    "We will now build new vocabularies following the previous observations and finally transform all `*_DESCRIPTION` columns into their vectorial representation. Note that the output of the `CountVectorizer.transform` method will be a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8309d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "vectorizers = {}\n",
    "\n",
    "# regular expression that matches every number\n",
    "number_re_pattern = re.compile(\"\\d+\")\n",
    "\n",
    "for c in text_cols:\n",
    "    vectorizers[c] = CountVectorizer(\n",
    "        lowercase=True,\n",
    "        stop_words=\"english\",  # words in this list will be ignored\n",
    "        min_df=10,             # minimum number of word occurrencies\n",
    "        preprocessor=lambda x: re.sub(number_re_pattern, \"numbertoken\", x.lower())\n",
    "    ).fit(X_train[c].fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1e3ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "vectorizers[\"HOTWATER_DESCRIPTION\"].transform([\"Electric immersion, standard tariff\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e263961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing HOTWATER_DESCRIPTION\n",
      "X_train shape = (536393, 80)\n",
      "X_test shape = (536393, 80)\n",
      "\n",
      "Vectorizing FLOOR_DESCRIPTION\n",
      "X_train shape = (536393, 106)\n",
      "X_test shape = (536393, 106)\n",
      "\n",
      "Vectorizing WINDOWS_DESCRIPTION\n",
      "X_train shape = (536393, 126)\n",
      "X_test shape = (536393, 126)\n",
      "\n",
      "Vectorizing WALLS_DESCRIPTION\n",
      "X_train shape = (536393, 157)\n",
      "X_test shape = (536393, 157)\n",
      "\n",
      "Vectorizing SECONDHEAT_DESCRIPTION\n",
      "X_train shape = (536393, 181)\n",
      "X_test shape = (536393, 181)\n",
      "\n",
      "Vectorizing ROOF_DESCRIPTION\n",
      "X_train shape = (536393, 215)\n",
      "X_test shape = (536393, 215)\n",
      "\n",
      "Vectorizing MAINHEAT_DESCRIPTION\n",
      "X_train shape = (536393, 277)\n",
      "X_test shape = (536393, 277)\n",
      "\n",
      "Vectorizing MAINHEATCONT_DESCRIPTION\n",
      "X_train shape = (536393, 322)\n",
      "X_test shape = (536393, 322)\n",
      "\n",
      "Vectorizing LIGHTING_DESCRIPTION\n",
      "X_train shape = (536393, 333)\n",
      "X_test shape = (536393, 333)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorized_column_names = []\n",
    "\n",
    "for c in text_cols:\n",
    "    print(f\"Vectorizing {c}\")\n",
    "    \n",
    "    # build column names as <column>_<word>. For example \"HOTWATER_DESCRIPTION_main\"\n",
    "    col_names = [f\"{c}_{name}\" for name in vectorizers[c].get_feature_names_out()]\n",
    "    vectorized_column_names += col_names\n",
    "    \n",
    "    # add all vectorized columns to X_train\n",
    "    X_train = pd.concat([\n",
    "        X_train.drop(columns=[c]),  # drop the original text column\n",
    "        pd.DataFrame(               # build a dataframe on top of the matrix output of the vectorizer\n",
    "            vectorizers[c].transform(X_train[c].fillna(\"\")).todense(),\n",
    "            columns=col_names,      # using the column names we built before\n",
    "            index=X_train.index,    # and using the same index of \n",
    "        ).astype(\"int8\")            # we have only small numbers, we can use a smaller data type\n",
    "    ], axis=1)\n",
    "\n",
    "    # same for X_test\n",
    "    X_test = pd.concat([\n",
    "        X_test.drop(columns=[c]),\n",
    "        pd.DataFrame(\n",
    "            vectorizers[c].transform(X_test[c].fillna(\"\")).todense(),\n",
    "            columns=col_names,\n",
    "            index=X_test.index,\n",
    "        ).astype(\"int8\")], axis=1\n",
    "    )\n",
    "    print(f\"X_train shape = {X_train.shape}\")\n",
    "    print(f\"X_test shape = {X_train.shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319a819",
   "metadata": {},
   "source": [
    "## Categorical encoding\n",
    "\n",
    "As a last preprocessing step, we encode categorical variables in the usual [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80397537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CITY',\n",
       " 'PROPERTY_TYPE',\n",
       " 'BUILT_FORM',\n",
       " 'CONSTRUCTION_AGE_BAND',\n",
       " 'ENERGY_TARIFF',\n",
       " 'MAINS_GAS_FLAG',\n",
       " 'FLOOR_LEVEL',\n",
       " 'FLAT_TOP_STOREY',\n",
       " 'MAIN_HEATING_CONTROLS',\n",
       " 'GLAZED_TYPE',\n",
       " 'GLAZED_AREA',\n",
       " 'MAIN_FUEL',\n",
       " 'SOLAR_WATER_HEATING_FLAG',\n",
       " 'MECHANICAL_VENTILATION']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = X_train.select_dtypes(\"object\").columns.tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b37a6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from impactdeal.preprocessing import CategoryReducer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "X_train[categorical_cols] = encoder.fit_transform(X_train[categorical_cols].astype(str))\n",
    "X_test[categorical_cols] = encoder.transform(X_test[categorical_cols].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e179c8e4",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now we are ready to train a [HistGradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html)!\n",
    "\n",
    "This dataset has a lot of rows and now, after our text encoding, also lots of columns. Therefore model fitting will take some time. Also, we will skip the cross-validated hyperameter search, as it would take days on our local machines or on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "997e608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 1.286 GB of training data: 5.435 s\n",
      "Binning 0.143 GB of validation data: 0.281 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 1.33827, val loss: 1.33896, in 2.892s\n",
      "[2/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 1.29926, val loss: 1.30248, in 3.503s\n",
      "[3/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 1.25467, val loss: 1.25553, in 3.871s\n",
      "[4/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 1.22135, val loss: 1.22237, in 2.840s\n",
      "[5/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 1.18956, val loss: 1.19135, in 3.031s\n",
      "[6/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 1.16010, val loss: 1.16299, in 3.179s\n",
      "[7/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 1.13385, val loss: 1.13635, in 3.266s\n",
      "[8/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 1.10975, val loss: 1.11092, in 2.834s\n",
      "[9/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 1.08815, val loss: 1.08933, in 2.854s\n",
      "[10/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 1.06796, val loss: 1.06925, in 3.548s\n",
      "[11/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 1.04918, val loss: 1.05057, in 3.816s\n",
      "[12/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 1.03158, val loss: 1.03300, in 3.600s\n",
      "[13/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 1.01527, val loss: 1.01682, in 3.245s\n",
      "[14/5000] 7 trees, 217 leaves (31 on avg), max depth = 10, train loss: 1.00276, val loss: 1.01050, in 3.157s\n",
      "[15/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.98576, val loss: 0.98956, in 3.762s\n",
      "[16/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.97233, val loss: 0.97618, in 5.120s\n",
      "[17/5000] 7 trees, 217 leaves (31 on avg), max depth = 22, train loss: 0.95937, val loss: 0.96335, in 4.265s\n",
      "[18/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.94762, val loss: 0.95168, in 3.553s\n",
      "[19/5000] 7 trees, 217 leaves (31 on avg), max depth = 10, train loss: 0.93633, val loss: 0.94045, in 4.076s\n",
      "[20/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.92558, val loss: 0.92991, in 3.280s\n",
      "[21/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.91548, val loss: 0.91991, in 3.710s\n",
      "[22/5000] 7 trees, 217 leaves (31 on avg), max depth = 10, train loss: 0.90603, val loss: 0.91048, in 3.678s\n",
      "[23/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.89694, val loss: 0.90147, in 3.308s\n",
      "[24/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.88809, val loss: 0.89267, in 3.614s\n",
      "[25/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.87952, val loss: 0.88432, in 4.147s\n",
      "[26/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.87135, val loss: 0.87632, in 3.658s\n",
      "[27/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.86343, val loss: 0.86866, in 3.666s\n",
      "[28/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.85600, val loss: 0.86137, in 4.104s\n",
      "[29/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.84912, val loss: 0.85460, in 3.866s\n",
      "[30/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.84259, val loss: 0.84807, in 3.604s\n",
      "[31/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.83613, val loss: 0.84168, in 3.705s\n",
      "[32/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.83012, val loss: 0.83567, in 3.661s\n",
      "[33/5000] 7 trees, 217 leaves (31 on avg), max depth = 10, train loss: 0.82437, val loss: 0.82997, in 3.879s\n",
      "[34/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.81849, val loss: 0.82340, in 3.797s\n",
      "[35/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.81278, val loss: 0.81694, in 4.259s\n",
      "[36/5000] 7 trees, 217 leaves (31 on avg), max depth = 10, train loss: 0.80751, val loss: 0.81153, in 3.422s\n",
      "[37/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.80236, val loss: 0.80642, in 3.141s\n",
      "[38/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.79733, val loss: 0.80156, in 3.522s\n",
      "[39/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.79215, val loss: 0.79646, in 3.316s\n",
      "[40/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.78755, val loss: 0.79193, in 3.677s\n",
      "[41/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.78308, val loss: 0.78760, in 3.455s\n",
      "[42/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.77880, val loss: 0.78341, in 3.589s\n",
      "[43/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.77453, val loss: 0.77919, in 4.114s\n",
      "[44/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.77073, val loss: 0.77544, in 3.799s\n",
      "[45/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.76685, val loss: 0.77169, in 3.771s\n",
      "[46/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.76318, val loss: 0.76810, in 3.741s\n",
      "[47/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.75953, val loss: 0.76449, in 3.909s\n",
      "[48/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.75610, val loss: 0.76115, in 3.688s\n",
      "[49/5000] 7 trees, 217 leaves (31 on avg), max depth = 10, train loss: 0.75258, val loss: 0.75770, in 3.824s\n",
      "[50/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.74944, val loss: 0.75455, in 4.399s\n",
      "[51/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.74635, val loss: 0.75151, in 3.544s\n",
      "[52/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.74325, val loss: 0.74846, in 4.420s\n",
      "[53/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.74036, val loss: 0.74565, in 4.150s\n",
      "[54/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.73717, val loss: 0.74250, in 4.046s\n",
      "[55/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.73440, val loss: 0.73982, in 4.554s\n",
      "[56/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.73160, val loss: 0.73706, in 3.842s\n",
      "[57/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.72878, val loss: 0.73432, in 3.959s\n",
      "[58/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.72631, val loss: 0.73191, in 4.069s\n",
      "[59/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.72379, val loss: 0.72953, in 3.829s\n",
      "[60/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.72124, val loss: 0.72702, in 3.842s\n",
      "[61/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.71871, val loss: 0.72454, in 3.802s\n",
      "[62/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.71634, val loss: 0.72219, in 3.326s\n",
      "[63/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.71374, val loss: 0.71970, in 4.163s\n",
      "[64/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.71143, val loss: 0.71741, in 4.308s\n",
      "[65/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.70918, val loss: 0.71521, in 3.745s\n",
      "[66/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.70691, val loss: 0.71301, in 3.643s\n",
      "[67/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.70463, val loss: 0.71077, in 4.214s\n",
      "[68/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.70258, val loss: 0.70874, in 3.725s\n",
      "[69/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.70035, val loss: 0.70660, in 4.563s\n",
      "[70/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.69825, val loss: 0.70462, in 3.520s\n",
      "[71/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.69632, val loss: 0.70274, in 4.065s\n",
      "[72/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.69440, val loss: 0.70097, in 4.146s\n",
      "[73/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.69255, val loss: 0.69913, in 3.690s\n",
      "[74/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.69073, val loss: 0.69740, in 4.459s\n",
      "[75/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.68892, val loss: 0.69561, in 3.706s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.68727, val loss: 0.69407, in 3.204s\n",
      "[77/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.68545, val loss: 0.69227, in 3.719s\n",
      "[78/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.68351, val loss: 0.69036, in 3.844s\n",
      "[79/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.68183, val loss: 0.68878, in 3.284s\n",
      "[80/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.68020, val loss: 0.68724, in 3.622s\n",
      "[81/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.67857, val loss: 0.68566, in 4.140s\n",
      "[82/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.67687, val loss: 0.68405, in 4.211s\n",
      "[83/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.67537, val loss: 0.68267, in 4.872s\n",
      "[84/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.67395, val loss: 0.68133, in 3.626s\n",
      "[85/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.67238, val loss: 0.67983, in 3.725s\n",
      "[86/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.67099, val loss: 0.67858, in 4.306s\n",
      "[87/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.66946, val loss: 0.67708, in 3.545s\n",
      "[88/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.66815, val loss: 0.67583, in 3.308s\n",
      "[89/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.66680, val loss: 0.67457, in 4.119s\n",
      "[90/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.66546, val loss: 0.67329, in 3.970s\n",
      "[91/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.66418, val loss: 0.67203, in 3.260s\n",
      "[92/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.66289, val loss: 0.67080, in 4.036s\n",
      "[93/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.66155, val loss: 0.66951, in 3.541s\n",
      "[94/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.66027, val loss: 0.66835, in 3.259s\n",
      "[95/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.65897, val loss: 0.66707, in 3.519s\n",
      "[96/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.65778, val loss: 0.66601, in 4.199s\n",
      "[97/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.65644, val loss: 0.66473, in 3.535s\n",
      "[98/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.65526, val loss: 0.66365, in 4.456s\n",
      "[99/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.65408, val loss: 0.66254, in 3.843s\n",
      "[100/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.65296, val loss: 0.66151, in 4.023s\n",
      "[101/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.65174, val loss: 0.66037, in 4.300s\n",
      "[102/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.65050, val loss: 0.65922, in 3.622s\n",
      "[103/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.64927, val loss: 0.65809, in 3.427s\n",
      "[104/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.64815, val loss: 0.65708, in 3.263s\n",
      "[105/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.64689, val loss: 0.65593, in 3.209s\n",
      "[106/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.64583, val loss: 0.65499, in 3.346s\n",
      "[107/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.64481, val loss: 0.65401, in 3.253s\n",
      "[108/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.64375, val loss: 0.65301, in 3.345s\n",
      "[109/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.64263, val loss: 0.65198, in 3.603s\n",
      "[110/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.64175, val loss: 0.65117, in 3.685s\n",
      "[111/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.64074, val loss: 0.65020, in 3.800s\n",
      "[112/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.63980, val loss: 0.64929, in 3.388s\n",
      "[113/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.63884, val loss: 0.64835, in 3.268s\n",
      "[114/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.63791, val loss: 0.64749, in 3.297s\n",
      "[115/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.63700, val loss: 0.64668, in 3.454s\n",
      "[116/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.63603, val loss: 0.64573, in 3.965s\n",
      "[117/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.63511, val loss: 0.64484, in 3.957s\n",
      "[118/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.63425, val loss: 0.64406, in 4.001s\n",
      "[119/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.63333, val loss: 0.64317, in 4.371s\n",
      "[120/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.63242, val loss: 0.64230, in 4.073s\n",
      "[121/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.63160, val loss: 0.64158, in 3.832s\n",
      "[122/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.63077, val loss: 0.64081, in 4.102s\n",
      "[123/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.62993, val loss: 0.64005, in 4.275s\n",
      "[124/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.62911, val loss: 0.63931, in 3.876s\n",
      "[125/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.62823, val loss: 0.63848, in 3.597s\n",
      "[126/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.62743, val loss: 0.63774, in 3.682s\n",
      "[127/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.62668, val loss: 0.63704, in 3.901s\n",
      "[128/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.62585, val loss: 0.63624, in 4.445s\n",
      "[129/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.62504, val loss: 0.63549, in 3.477s\n",
      "[130/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.62426, val loss: 0.63474, in 3.475s\n",
      "[131/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.62350, val loss: 0.63406, in 3.130s\n",
      "[132/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.62278, val loss: 0.63338, in 3.978s\n",
      "[133/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.62198, val loss: 0.63266, in 4.720s\n",
      "[134/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.62120, val loss: 0.63193, in 4.214s\n",
      "[135/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.62046, val loss: 0.63126, in 4.388s\n",
      "[136/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.61978, val loss: 0.63065, in 5.184s\n",
      "[137/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.61907, val loss: 0.62998, in 5.623s\n",
      "[138/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.61834, val loss: 0.62930, in 4.939s\n",
      "[139/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.61756, val loss: 0.62857, in 3.819s\n",
      "[140/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.61687, val loss: 0.62790, in 3.240s\n",
      "[141/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.61625, val loss: 0.62733, in 3.723s\n",
      "[142/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.61557, val loss: 0.62670, in 6.342s\n",
      "[143/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.61491, val loss: 0.62608, in 6.282s\n",
      "[144/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.61424, val loss: 0.62544, in 3.674s\n",
      "[145/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.61354, val loss: 0.62480, in 16.230s\n",
      "[146/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.61286, val loss: 0.62418, in 30.067s\n",
      "[147/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.61219, val loss: 0.62356, in 17.415s\n",
      "[148/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.61156, val loss: 0.62299, in 9.959s\n",
      "[149/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.61097, val loss: 0.62247, in 5.852s\n",
      "[150/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.61033, val loss: 0.62192, in 4.774s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.60967, val loss: 0.62134, in 4.126s\n",
      "[152/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.60906, val loss: 0.62077, in 3.731s\n",
      "[153/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.60842, val loss: 0.62018, in 3.283s\n",
      "[154/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.60784, val loss: 0.61964, in 3.182s\n",
      "[155/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.60728, val loss: 0.61913, in 6.941s\n",
      "[156/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.60663, val loss: 0.61851, in 3.123s\n",
      "[157/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.60604, val loss: 0.61798, in 3.070s\n",
      "[158/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.60548, val loss: 0.61749, in 3.113s\n",
      "[159/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.60488, val loss: 0.61694, in 3.356s\n",
      "[160/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.60434, val loss: 0.61643, in 3.038s\n",
      "[161/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.60374, val loss: 0.61589, in 3.065s\n",
      "[162/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.60313, val loss: 0.61535, in 3.617s\n",
      "[163/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.60250, val loss: 0.61477, in 3.258s\n",
      "[164/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.60195, val loss: 0.61430, in 3.114s\n",
      "[165/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.60139, val loss: 0.61379, in 3.047s\n",
      "[166/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.60110, val loss: 0.61370, in 3.077s\n",
      "[167/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.60038, val loss: 0.61302, in 3.209s\n",
      "[168/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.59984, val loss: 0.61254, in 3.143s\n",
      "[169/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.59932, val loss: 0.61207, in 3.373s\n",
      "[170/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.59877, val loss: 0.61157, in 3.203s\n",
      "[171/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.59827, val loss: 0.61112, in 3.050s\n",
      "[172/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.59773, val loss: 0.61063, in 2.958s\n",
      "[173/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.59711, val loss: 0.61009, in 3.146s\n",
      "[174/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.59662, val loss: 0.60967, in 3.071s\n",
      "[175/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.59612, val loss: 0.60920, in 3.202s\n",
      "[176/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.59562, val loss: 0.60872, in 3.285s\n",
      "[177/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.59508, val loss: 0.60823, in 4.435s\n",
      "[178/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.59462, val loss: 0.60780, in 3.418s\n",
      "[179/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.59411, val loss: 0.60735, in 3.696s\n",
      "[180/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.59361, val loss: 0.60692, in 3.555s\n",
      "[181/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.59309, val loss: 0.60642, in 3.772s\n",
      "[182/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.59261, val loss: 0.60600, in 3.575s\n",
      "[183/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.59218, val loss: 0.60562, in 3.308s\n",
      "[184/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.59163, val loss: 0.60515, in 3.755s\n",
      "[185/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.59120, val loss: 0.60477, in 3.424s\n",
      "[186/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.59073, val loss: 0.60435, in 3.620s\n",
      "[187/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.59028, val loss: 0.60395, in 3.618s\n",
      "[188/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.58985, val loss: 0.60365, in 3.761s\n",
      "[189/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.58938, val loss: 0.60323, in 3.255s\n",
      "[190/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.58892, val loss: 0.60279, in 3.356s\n",
      "[191/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.58848, val loss: 0.60241, in 3.291s\n",
      "[192/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.58801, val loss: 0.60200, in 3.056s\n",
      "[193/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.58757, val loss: 0.60164, in 3.677s\n",
      "[194/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.58713, val loss: 0.60124, in 3.381s\n",
      "[195/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.58663, val loss: 0.60079, in 3.404s\n",
      "[196/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.58614, val loss: 0.60036, in 3.492s\n",
      "[197/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.58569, val loss: 0.59997, in 3.381s\n",
      "[198/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.58530, val loss: 0.59964, in 3.186s\n",
      "[199/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.58482, val loss: 0.59921, in 3.818s\n",
      "[200/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.58438, val loss: 0.59881, in 3.317s\n",
      "[201/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.58394, val loss: 0.59844, in 3.002s\n",
      "[202/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.58348, val loss: 0.59801, in 3.345s\n",
      "[203/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.58305, val loss: 0.59759, in 2.985s\n",
      "[204/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.58267, val loss: 0.59725, in 3.275s\n",
      "[205/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.58230, val loss: 0.59688, in 3.194s\n",
      "[206/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.58187, val loss: 0.59651, in 3.295s\n",
      "[207/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.58148, val loss: 0.59615, in 3.496s\n",
      "[208/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.58109, val loss: 0.59582, in 4.189s\n",
      "[209/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.58068, val loss: 0.59548, in 3.560s\n",
      "[210/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.58024, val loss: 0.59505, in 3.621s\n",
      "[211/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.57982, val loss: 0.59470, in 4.060s\n",
      "[212/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.57949, val loss: 0.59441, in 3.128s\n",
      "[213/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.57911, val loss: 0.59409, in 3.593s\n",
      "[214/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.57873, val loss: 0.59374, in 3.427s\n",
      "[215/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.57836, val loss: 0.59343, in 3.582s\n",
      "[216/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.57797, val loss: 0.59310, in 4.287s\n",
      "[217/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.57758, val loss: 0.59276, in 3.681s\n",
      "[218/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.57720, val loss: 0.59243, in 3.641s\n",
      "[219/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.57687, val loss: 0.59215, in 3.517s\n",
      "[220/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.57652, val loss: 0.59184, in 4.872s\n",
      "[221/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.57642, val loss: 0.59154, in 3.689s\n",
      "[222/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.57574, val loss: 0.59121, in 3.449s\n",
      "[223/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.57535, val loss: 0.59085, in 3.718s\n",
      "[224/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.57497, val loss: 0.59054, in 5.569s\n",
      "[225/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.57461, val loss: 0.59022, in 6.197s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.57430, val loss: 0.58997, in 4.166s\n",
      "[227/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.57394, val loss: 0.58965, in 3.420s\n",
      "[228/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.57356, val loss: 0.58931, in 3.233s\n",
      "[229/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.57321, val loss: 0.58902, in 3.299s\n",
      "[230/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.57286, val loss: 0.58871, in 3.519s\n",
      "[231/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.57253, val loss: 0.58843, in 3.625s\n",
      "[232/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.57215, val loss: 0.58810, in 3.986s\n",
      "[233/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.57181, val loss: 0.58781, in 4.450s\n",
      "[234/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.57145, val loss: 0.58753, in 3.833s\n",
      "[235/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.57111, val loss: 0.58724, in 3.215s\n",
      "[236/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.57075, val loss: 0.58694, in 3.659s\n",
      "[237/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.57042, val loss: 0.58662, in 5.790s\n",
      "[238/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.57010, val loss: 0.58637, in 3.178s\n",
      "[239/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56978, val loss: 0.58610, in 4.536s\n",
      "[240/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.56947, val loss: 0.58585, in 4.557s\n",
      "[241/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56916, val loss: 0.58556, in 4.028s\n",
      "[242/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.56881, val loss: 0.58527, in 4.683s\n",
      "[243/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56848, val loss: 0.58500, in 3.509s\n",
      "[244/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56815, val loss: 0.58471, in 3.418s\n",
      "[245/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.56784, val loss: 0.58445, in 3.571s\n",
      "[246/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.56752, val loss: 0.58419, in 2.920s\n",
      "[247/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.56721, val loss: 0.58395, in 3.579s\n",
      "[248/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56690, val loss: 0.58367, in 3.254s\n",
      "[249/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56656, val loss: 0.58336, in 3.014s\n",
      "[250/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.56625, val loss: 0.58306, in 2.913s\n",
      "[251/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56591, val loss: 0.58279, in 3.237s\n",
      "[252/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56560, val loss: 0.58254, in 3.033s\n",
      "[253/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56528, val loss: 0.58229, in 2.995s\n",
      "[254/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.56496, val loss: 0.58202, in 3.094s\n",
      "[255/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.56466, val loss: 0.58179, in 3.302s\n",
      "[256/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.56438, val loss: 0.58158, in 3.235s\n",
      "[257/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.56410, val loss: 0.58135, in 2.979s\n",
      "[258/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.56380, val loss: 0.58111, in 3.036s\n",
      "[259/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56350, val loss: 0.58086, in 3.537s\n",
      "[260/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.56321, val loss: 0.58062, in 3.652s\n",
      "[261/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.56290, val loss: 0.58039, in 3.291s\n",
      "[262/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.56263, val loss: 0.58016, in 3.430s\n",
      "[263/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.56231, val loss: 0.57989, in 4.857s\n",
      "[264/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.56201, val loss: 0.57964, in 3.250s\n",
      "[265/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56173, val loss: 0.57939, in 3.198s\n",
      "[266/5000] 7 trees, 217 leaves (31 on avg), max depth = 21, train loss: 0.56145, val loss: 0.57919, in 3.413s\n",
      "[267/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.56115, val loss: 0.57894, in 3.260s\n",
      "[268/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.56089, val loss: 0.57875, in 2.930s\n",
      "[269/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.56059, val loss: 0.57850, in 3.119s\n",
      "[270/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.56031, val loss: 0.57826, in 2.882s\n",
      "[271/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.56001, val loss: 0.57802, in 9.492s\n",
      "[272/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.55973, val loss: 0.57780, in 20.221s\n",
      "[273/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.55946, val loss: 0.57760, in 5.516s\n",
      "[274/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.55920, val loss: 0.57738, in 3.112s\n",
      "[275/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.55892, val loss: 0.57717, in 3.351s\n",
      "[276/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.55867, val loss: 0.57698, in 3.118s\n",
      "[277/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.55837, val loss: 0.57675, in 3.088s\n",
      "[278/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.55809, val loss: 0.57652, in 3.701s\n",
      "[279/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.55783, val loss: 0.57632, in 3.154s\n",
      "[280/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.55756, val loss: 0.57611, in 3.464s\n",
      "[281/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.55729, val loss: 0.57588, in 3.503s\n",
      "[282/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.55704, val loss: 0.57568, in 3.473s\n",
      "[283/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.55678, val loss: 0.57550, in 5.698s\n",
      "[284/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.55652, val loss: 0.57531, in 3.365s\n",
      "[285/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.55623, val loss: 0.57507, in 7.460s\n",
      "[286/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.55596, val loss: 0.57487, in 4.061s\n",
      "[287/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.55571, val loss: 0.57466, in 3.092s\n",
      "[288/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.55545, val loss: 0.57446, in 4.728s\n",
      "[289/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.55520, val loss: 0.57427, in 3.502s\n",
      "[290/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.55494, val loss: 0.57405, in 3.429s\n",
      "[291/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.55467, val loss: 0.57383, in 3.223s\n",
      "[292/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.55445, val loss: 0.57367, in 3.175s\n",
      "[293/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.55418, val loss: 0.57344, in 2.909s\n",
      "[294/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.55392, val loss: 0.57323, in 3.003s\n",
      "[295/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.55366, val loss: 0.57304, in 3.606s\n",
      "[296/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.55340, val loss: 0.57283, in 5.040s\n",
      "[297/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.55315, val loss: 0.57263, in 3.754s\n",
      "[298/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.55288, val loss: 0.57242, in 3.107s\n",
      "[299/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.55264, val loss: 0.57224, in 3.006s\n",
      "[300/5000] 7 trees, 217 leaves (31 on avg), max depth = 22, train loss: 0.55238, val loss: 0.57204, in 3.062s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[301/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.55212, val loss: 0.57185, in 3.067s\n",
      "[302/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.55189, val loss: 0.57168, in 4.511s\n",
      "[303/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.55167, val loss: 0.57153, in 3.270s\n",
      "[304/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.55138, val loss: 0.57130, in 5.785s\n",
      "[305/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.55113, val loss: 0.57110, in 3.939s\n",
      "[306/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.55087, val loss: 0.57089, in 3.968s\n",
      "[307/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.55060, val loss: 0.57070, in 2.955s\n",
      "[308/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.55039, val loss: 0.57053, in 2.886s\n",
      "[309/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.55015, val loss: 0.57037, in 2.925s\n",
      "[310/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.54991, val loss: 0.57017, in 3.620s\n",
      "[311/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.54969, val loss: 0.56999, in 3.952s\n",
      "[312/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54941, val loss: 0.56977, in 3.588s\n",
      "[313/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54919, val loss: 0.56961, in 3.043s\n",
      "[314/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54897, val loss: 0.56944, in 3.079s\n",
      "[315/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54875, val loss: 0.56925, in 3.081s\n",
      "[316/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54853, val loss: 0.56910, in 4.185s\n",
      "[317/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.54831, val loss: 0.56893, in 5.563s\n",
      "[318/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54806, val loss: 0.56872, in 3.288s\n",
      "[319/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54783, val loss: 0.56855, in 3.363s\n",
      "[320/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54761, val loss: 0.56840, in 3.459s\n",
      "[321/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.54740, val loss: 0.56828, in 9.575s\n",
      "[322/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54718, val loss: 0.56808, in 5.009s\n",
      "[323/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.54694, val loss: 0.56790, in 3.369s\n",
      "[324/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54672, val loss: 0.56773, in 2.843s\n",
      "[325/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54650, val loss: 0.56756, in 3.425s\n",
      "[326/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54628, val loss: 0.56739, in 4.515s\n",
      "[327/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.54605, val loss: 0.56717, in 4.167s\n",
      "[328/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54584, val loss: 0.56701, in 3.391s\n",
      "[329/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54564, val loss: 0.56686, in 5.318s\n",
      "[330/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54541, val loss: 0.56669, in 6.100s\n",
      "[331/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54520, val loss: 0.56650, in 9.034s\n",
      "[332/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54502, val loss: 0.56637, in 3.515s\n",
      "[333/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54481, val loss: 0.56620, in 4.640s\n",
      "[334/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54459, val loss: 0.56603, in 3.762s\n",
      "[335/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54436, val loss: 0.56584, in 4.140s\n",
      "[336/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54416, val loss: 0.56570, in 3.387s\n",
      "[337/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.54396, val loss: 0.56557, in 3.169s\n",
      "[338/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54371, val loss: 0.56537, in 3.631s\n",
      "[339/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54350, val loss: 0.56521, in 5.037s\n",
      "[340/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54330, val loss: 0.56507, in 3.883s\n",
      "[341/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54311, val loss: 0.56494, in 3.896s\n",
      "[342/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54291, val loss: 0.56479, in 3.461s\n",
      "[343/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.54269, val loss: 0.56463, in 3.374s\n",
      "[344/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.54249, val loss: 0.56448, in 4.148s\n",
      "[345/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.54227, val loss: 0.56430, in 3.117s\n",
      "[346/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54201, val loss: 0.56409, in 3.545s\n",
      "[347/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54181, val loss: 0.56396, in 3.587s\n",
      "[348/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54162, val loss: 0.56383, in 3.649s\n",
      "[349/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54142, val loss: 0.56369, in 3.339s\n",
      "[350/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.54122, val loss: 0.56356, in 3.643s\n",
      "[351/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54102, val loss: 0.56340, in 3.217s\n",
      "[352/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.54082, val loss: 0.56326, in 4.844s\n",
      "[353/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.54064, val loss: 0.56314, in 4.290s\n",
      "[354/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.54044, val loss: 0.56301, in 10.059s\n",
      "[355/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54024, val loss: 0.56284, in 13.144s\n",
      "[356/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.54004, val loss: 0.56270, in 7.976s\n",
      "[357/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53982, val loss: 0.56255, in 13.686s\n",
      "[358/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53963, val loss: 0.56241, in 13.853s\n",
      "[359/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.53944, val loss: 0.56227, in 14.839s\n",
      "[360/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.53924, val loss: 0.56214, in 10.620s\n",
      "[361/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53904, val loss: 0.56202, in 12.431s\n",
      "[362/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.53885, val loss: 0.56189, in 10.373s\n",
      "[363/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53864, val loss: 0.56173, in 5.223s\n",
      "[364/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53846, val loss: 0.56160, in 3.099s\n",
      "[365/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.53824, val loss: 0.56146, in 4.146s\n",
      "[366/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.53805, val loss: 0.56132, in 3.023s\n",
      "[367/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.53778, val loss: 0.56111, in 3.228s\n",
      "[368/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53760, val loss: 0.56098, in 4.702s\n",
      "[369/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.53743, val loss: 0.56086, in 4.937s\n",
      "[370/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53725, val loss: 0.56074, in 8.858s\n",
      "[371/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53708, val loss: 0.56064, in 2.933s\n",
      "[372/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53691, val loss: 0.56052, in 2.758s\n",
      "[373/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.53674, val loss: 0.56041, in 3.276s\n",
      "[374/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.53656, val loss: 0.56028, in 3.367s\n",
      "[375/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53638, val loss: 0.56015, in 6.421s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[376/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53621, val loss: 0.56004, in 2.655s\n",
      "[377/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.53602, val loss: 0.55987, in 3.468s\n",
      "[378/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53585, val loss: 0.55975, in 3.040s\n",
      "[379/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.53568, val loss: 0.55963, in 3.150s\n",
      "[380/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.53552, val loss: 0.55953, in 2.660s\n",
      "[381/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.53535, val loss: 0.55942, in 4.021s\n",
      "[382/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53517, val loss: 0.55930, in 5.043s\n",
      "[383/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53498, val loss: 0.55916, in 5.294s\n",
      "[384/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53480, val loss: 0.55901, in 2.722s\n",
      "[385/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53463, val loss: 0.55891, in 4.656s\n",
      "[386/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.53444, val loss: 0.55878, in 2.898s\n",
      "[387/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53427, val loss: 0.55866, in 2.651s\n",
      "[388/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.53410, val loss: 0.55855, in 3.002s\n",
      "[389/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53389, val loss: 0.55839, in 2.835s\n",
      "[390/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.53371, val loss: 0.55824, in 3.105s\n",
      "[391/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.53351, val loss: 0.55810, in 3.049s\n",
      "[392/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.53333, val loss: 0.55796, in 2.839s\n",
      "[393/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.53313, val loss: 0.55782, in 3.050s\n",
      "[394/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.53297, val loss: 0.55772, in 4.279s\n",
      "[395/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.53279, val loss: 0.55762, in 4.500s\n",
      "[396/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.53261, val loss: 0.55750, in 2.861s\n",
      "[397/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53246, val loss: 0.55743, in 2.678s\n",
      "[398/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.53230, val loss: 0.55732, in 2.558s\n",
      "[399/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.53212, val loss: 0.55719, in 2.750s\n",
      "[400/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53196, val loss: 0.55710, in 2.642s\n",
      "[401/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.53178, val loss: 0.55699, in 3.313s\n",
      "[402/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.53161, val loss: 0.55690, in 3.567s\n",
      "[403/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53145, val loss: 0.55680, in 2.967s\n",
      "[404/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.53128, val loss: 0.55668, in 3.746s\n",
      "[405/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.53114, val loss: 0.55659, in 4.097s\n",
      "[406/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.53098, val loss: 0.55649, in 2.968s\n",
      "[407/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.53082, val loss: 0.55637, in 3.104s\n",
      "[408/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.53065, val loss: 0.55625, in 2.742s\n",
      "[409/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.53051, val loss: 0.55616, in 3.377s\n",
      "[410/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.53035, val loss: 0.55603, in 3.319s\n",
      "[411/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.53019, val loss: 0.55593, in 3.024s\n",
      "[412/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52997, val loss: 0.55576, in 2.816s\n",
      "[413/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52982, val loss: 0.55568, in 2.600s\n",
      "[414/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.52966, val loss: 0.55559, in 2.550s\n",
      "[415/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52949, val loss: 0.55547, in 2.839s\n",
      "[416/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.52933, val loss: 0.55538, in 2.653s\n",
      "[417/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52918, val loss: 0.55527, in 2.720s\n",
      "[418/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.52902, val loss: 0.55518, in 2.758s\n",
      "[419/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52886, val loss: 0.55507, in 2.873s\n",
      "[420/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.52872, val loss: 0.55499, in 2.530s\n",
      "[421/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.52855, val loss: 0.55485, in 2.726s\n",
      "[422/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.52840, val loss: 0.55476, in 2.805s\n",
      "[423/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52822, val loss: 0.55464, in 2.587s\n",
      "[424/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.52805, val loss: 0.55454, in 3.777s\n",
      "[425/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52782, val loss: 0.55437, in 2.920s\n",
      "[426/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52767, val loss: 0.55428, in 2.856s\n",
      "[427/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.52751, val loss: 0.55420, in 2.714s\n",
      "[428/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52733, val loss: 0.55405, in 2.657s\n",
      "[429/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52718, val loss: 0.55394, in 2.608s\n",
      "[430/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52700, val loss: 0.55381, in 2.911s\n",
      "[431/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.52683, val loss: 0.55369, in 2.604s\n",
      "[432/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.52668, val loss: 0.55359, in 2.666s\n",
      "[433/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52652, val loss: 0.55347, in 2.818s\n",
      "[434/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52638, val loss: 0.55340, in 2.517s\n",
      "[435/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52619, val loss: 0.55329, in 2.911s\n",
      "[436/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.52605, val loss: 0.55321, in 2.503s\n",
      "[437/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52588, val loss: 0.55309, in 2.675s\n",
      "[438/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.52573, val loss: 0.55300, in 2.742s\n",
      "[439/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52558, val loss: 0.55289, in 2.551s\n",
      "[440/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52544, val loss: 0.55280, in 2.610s\n",
      "[441/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52528, val loss: 0.55270, in 2.608s\n",
      "[442/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52509, val loss: 0.55258, in 2.795s\n",
      "[443/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52496, val loss: 0.55249, in 2.550s\n",
      "[444/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52482, val loss: 0.55240, in 2.754s\n",
      "[445/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.52468, val loss: 0.55231, in 2.721s\n",
      "[446/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52454, val loss: 0.55223, in 2.619s\n",
      "[447/5000] 7 trees, 217 leaves (31 on avg), max depth = 21, train loss: 0.52438, val loss: 0.55211, in 2.776s\n",
      "[448/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52423, val loss: 0.55203, in 2.712s\n",
      "[449/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.52407, val loss: 0.55191, in 2.665s\n",
      "[450/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52393, val loss: 0.55183, in 2.617s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[451/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.52377, val loss: 0.55172, in 2.660s\n",
      "[452/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52363, val loss: 0.55163, in 2.663s\n",
      "[453/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52345, val loss: 0.55152, in 2.717s\n",
      "[454/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52330, val loss: 0.55141, in 2.601s\n",
      "[455/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.52316, val loss: 0.55131, in 2.657s\n",
      "[456/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52301, val loss: 0.55120, in 2.425s\n",
      "[457/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52287, val loss: 0.55114, in 2.664s\n",
      "[458/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.52275, val loss: 0.55107, in 2.655s\n",
      "[459/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52260, val loss: 0.55098, in 2.545s\n",
      "[460/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52247, val loss: 0.55092, in 2.463s\n",
      "[461/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.52231, val loss: 0.55081, in 2.960s\n",
      "[462/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.52217, val loss: 0.55073, in 3.608s\n",
      "[463/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52203, val loss: 0.55065, in 2.598s\n",
      "[464/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52188, val loss: 0.55055, in 2.774s\n",
      "[465/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.52172, val loss: 0.55043, in 3.474s\n",
      "[466/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52158, val loss: 0.55033, in 2.511s\n",
      "[467/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.52143, val loss: 0.55024, in 3.196s\n",
      "[468/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.52128, val loss: 0.55015, in 3.085s\n",
      "[469/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52114, val loss: 0.55007, in 3.642s\n",
      "[470/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52101, val loss: 0.54999, in 8.681s\n",
      "[471/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52088, val loss: 0.54992, in 7.440s\n",
      "[472/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.52075, val loss: 0.54983, in 10.360s\n",
      "[473/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.52059, val loss: 0.54972, in 7.002s\n",
      "[474/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.52047, val loss: 0.54966, in 2.912s\n",
      "[475/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.52033, val loss: 0.54959, in 3.044s\n",
      "[476/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.52020, val loss: 0.54951, in 2.858s\n",
      "[477/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.52005, val loss: 0.54940, in 5.400s\n",
      "[478/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51992, val loss: 0.54933, in 6.447s\n",
      "[479/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.51976, val loss: 0.54922, in 3.377s\n",
      "[480/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51962, val loss: 0.54913, in 4.980s\n",
      "[481/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.51949, val loss: 0.54902, in 5.592s\n",
      "[482/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.51938, val loss: 0.54896, in 2.529s\n",
      "[483/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51923, val loss: 0.54885, in 4.902s\n",
      "[484/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.51910, val loss: 0.54878, in 6.620s\n",
      "[485/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51896, val loss: 0.54869, in 4.100s\n",
      "[486/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51883, val loss: 0.54864, in 3.537s\n",
      "[487/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.51871, val loss: 0.54857, in 2.652s\n",
      "[488/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51858, val loss: 0.54851, in 2.816s\n",
      "[489/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.51844, val loss: 0.54843, in 2.712s\n",
      "[490/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.51831, val loss: 0.54835, in 2.816s\n",
      "[491/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51817, val loss: 0.54824, in 2.567s\n",
      "[492/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51802, val loss: 0.54813, in 3.619s\n",
      "[493/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51788, val loss: 0.54804, in 2.544s\n",
      "[494/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51773, val loss: 0.54793, in 2.726s\n",
      "[495/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51762, val loss: 0.54789, in 3.046s\n",
      "[496/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.51748, val loss: 0.54781, in 3.037s\n",
      "[497/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51735, val loss: 0.54774, in 4.680s\n",
      "[498/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51722, val loss: 0.54767, in 3.242s\n",
      "[499/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.51711, val loss: 0.54762, in 2.502s\n",
      "[500/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.51700, val loss: 0.54756, in 3.062s\n",
      "[501/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51688, val loss: 0.54750, in 2.399s\n",
      "[502/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.51673, val loss: 0.54740, in 3.573s\n",
      "[503/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51661, val loss: 0.54732, in 2.500s\n",
      "[504/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51647, val loss: 0.54722, in 2.612s\n",
      "[505/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.51633, val loss: 0.54715, in 2.730s\n",
      "[506/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51621, val loss: 0.54708, in 2.471s\n",
      "[507/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51608, val loss: 0.54701, in 2.474s\n",
      "[508/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.51597, val loss: 0.54695, in 2.647s\n",
      "[509/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51583, val loss: 0.54685, in 2.434s\n",
      "[510/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51569, val loss: 0.54677, in 2.503s\n",
      "[511/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51555, val loss: 0.54668, in 2.533s\n",
      "[512/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51541, val loss: 0.54659, in 2.579s\n",
      "[513/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51529, val loss: 0.54651, in 2.324s\n",
      "[514/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51514, val loss: 0.54642, in 2.693s\n",
      "[515/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51501, val loss: 0.54636, in 2.630s\n",
      "[516/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51490, val loss: 0.54632, in 2.484s\n",
      "[517/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51477, val loss: 0.54626, in 2.507s\n",
      "[518/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51465, val loss: 0.54618, in 2.870s\n",
      "[519/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51452, val loss: 0.54609, in 2.896s\n",
      "[520/5000] 7 trees, 217 leaves (31 on avg), max depth = 21, train loss: 0.51439, val loss: 0.54598, in 2.514s\n",
      "[521/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.51427, val loss: 0.54593, in 2.436s\n",
      "[522/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51416, val loss: 0.54584, in 2.506s\n",
      "[523/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51402, val loss: 0.54576, in 2.597s\n",
      "[524/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.51390, val loss: 0.54569, in 2.449s\n",
      "[525/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51378, val loss: 0.54563, in 2.822s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[526/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51366, val loss: 0.54554, in 2.372s\n",
      "[527/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.51353, val loss: 0.54546, in 2.477s\n",
      "[528/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.51339, val loss: 0.54538, in 2.468s\n",
      "[529/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51327, val loss: 0.54530, in 2.500s\n",
      "[530/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51313, val loss: 0.54523, in 2.570s\n",
      "[531/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.51299, val loss: 0.54515, in 2.420s\n",
      "[532/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.51288, val loss: 0.54509, in 2.655s\n",
      "[533/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.51277, val loss: 0.54505, in 2.655s\n",
      "[534/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51263, val loss: 0.54496, in 2.664s\n",
      "[535/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51250, val loss: 0.54488, in 2.544s\n",
      "[536/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.51238, val loss: 0.54481, in 2.524s\n",
      "[537/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51226, val loss: 0.54475, in 2.633s\n",
      "[538/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.51214, val loss: 0.54471, in 2.346s\n",
      "[539/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.51200, val loss: 0.54463, in 2.454s\n",
      "[540/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51186, val loss: 0.54456, in 2.673s\n",
      "[541/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51171, val loss: 0.54445, in 2.545s\n",
      "[542/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51159, val loss: 0.54439, in 2.190s\n",
      "[543/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51148, val loss: 0.54432, in 3.114s\n",
      "[544/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51137, val loss: 0.54427, in 2.718s\n",
      "[545/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.51126, val loss: 0.54421, in 2.228s\n",
      "[546/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.51115, val loss: 0.54416, in 2.679s\n",
      "[547/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51103, val loss: 0.54409, in 2.318s\n",
      "[548/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.51090, val loss: 0.54401, in 2.198s\n",
      "[549/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51077, val loss: 0.54393, in 2.601s\n",
      "[550/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51065, val loss: 0.54388, in 2.320s\n",
      "[551/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.51054, val loss: 0.54383, in 2.440s\n",
      "[552/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51042, val loss: 0.54374, in 2.917s\n",
      "[553/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.51032, val loss: 0.54370, in 2.313s\n",
      "[554/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.51016, val loss: 0.54359, in 3.130s\n",
      "[555/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.51005, val loss: 0.54353, in 2.605s\n",
      "[556/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50993, val loss: 0.54345, in 2.603s\n",
      "[557/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50983, val loss: 0.54339, in 2.284s\n",
      "[558/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50971, val loss: 0.54333, in 2.372s\n",
      "[559/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50958, val loss: 0.54325, in 2.264s\n",
      "[560/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50947, val loss: 0.54319, in 2.487s\n",
      "[561/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50935, val loss: 0.54312, in 2.500s\n",
      "[562/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50922, val loss: 0.54307, in 2.900s\n",
      "[563/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.50911, val loss: 0.54301, in 2.178s\n",
      "[564/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50898, val loss: 0.54294, in 2.626s\n",
      "[565/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50888, val loss: 0.54290, in 2.419s\n",
      "[566/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50875, val loss: 0.54281, in 2.409s\n",
      "[567/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.50864, val loss: 0.54276, in 2.306s\n",
      "[568/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50853, val loss: 0.54268, in 2.885s\n",
      "[569/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50844, val loss: 0.54265, in 2.288s\n",
      "[570/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50832, val loss: 0.54258, in 2.451s\n",
      "[571/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50821, val loss: 0.54255, in 2.482s\n",
      "[572/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50810, val loss: 0.54248, in 3.055s\n",
      "[573/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50799, val loss: 0.54242, in 2.744s\n",
      "[574/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50787, val loss: 0.54234, in 2.763s\n",
      "[575/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50776, val loss: 0.54228, in 2.724s\n",
      "[576/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50763, val loss: 0.54221, in 2.435s\n",
      "[577/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50752, val loss: 0.54215, in 2.291s\n",
      "[578/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50743, val loss: 0.54211, in 2.603s\n",
      "[579/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.50732, val loss: 0.54203, in 2.533s\n",
      "[580/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50722, val loss: 0.54198, in 2.407s\n",
      "[581/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50711, val loss: 0.54194, in 2.660s\n",
      "[582/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50701, val loss: 0.54191, in 2.420s\n",
      "[583/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50691, val loss: 0.54186, in 2.615s\n",
      "[584/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50681, val loss: 0.54181, in 3.074s\n",
      "[585/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.50669, val loss: 0.54175, in 2.430s\n",
      "[586/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50658, val loss: 0.54170, in 2.685s\n",
      "[587/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50647, val loss: 0.54165, in 2.271s\n",
      "[588/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50636, val loss: 0.54160, in 2.452s\n",
      "[589/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50624, val loss: 0.54153, in 3.589s\n",
      "[590/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.50612, val loss: 0.54146, in 2.798s\n",
      "[591/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50600, val loss: 0.54140, in 4.661s\n",
      "[592/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50589, val loss: 0.54134, in 7.065s\n",
      "[593/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50578, val loss: 0.54128, in 2.580s\n",
      "[594/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50568, val loss: 0.54121, in 2.484s\n",
      "[595/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50558, val loss: 0.54115, in 2.434s\n",
      "[596/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50548, val loss: 0.54111, in 2.882s\n",
      "[597/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50538, val loss: 0.54106, in 2.234s\n",
      "[598/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50527, val loss: 0.54100, in 3.826s\n",
      "[599/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50517, val loss: 0.54095, in 2.731s\n",
      "[600/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50506, val loss: 0.54089, in 2.490s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[601/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50495, val loss: 0.54083, in 2.433s\n",
      "[602/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50484, val loss: 0.54078, in 2.679s\n",
      "[603/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50472, val loss: 0.54072, in 2.356s\n",
      "[604/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.50463, val loss: 0.54068, in 2.307s\n",
      "[605/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50452, val loss: 0.54064, in 2.416s\n",
      "[606/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50441, val loss: 0.54059, in 2.508s\n",
      "[607/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50430, val loss: 0.54053, in 2.770s\n",
      "[608/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50420, val loss: 0.54047, in 2.569s\n",
      "[609/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50410, val loss: 0.54041, in 2.311s\n",
      "[610/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.50399, val loss: 0.54036, in 2.406s\n",
      "[611/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50388, val loss: 0.54030, in 2.821s\n",
      "[612/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50376, val loss: 0.54023, in 2.468s\n",
      "[613/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50367, val loss: 0.54019, in 2.491s\n",
      "[614/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50358, val loss: 0.54015, in 2.259s\n",
      "[615/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50348, val loss: 0.54009, in 2.946s\n",
      "[616/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50338, val loss: 0.54004, in 2.781s\n",
      "[617/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50327, val loss: 0.53997, in 4.461s\n",
      "[618/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50316, val loss: 0.53990, in 3.446s\n",
      "[619/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50307, val loss: 0.53986, in 3.000s\n",
      "[620/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50297, val loss: 0.53981, in 2.545s\n",
      "[621/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.50287, val loss: 0.53975, in 2.229s\n",
      "[622/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50275, val loss: 0.53968, in 2.627s\n",
      "[623/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50265, val loss: 0.53961, in 2.841s\n",
      "[624/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50254, val loss: 0.53957, in 2.918s\n",
      "[625/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50243, val loss: 0.53951, in 2.844s\n",
      "[626/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50230, val loss: 0.53943, in 4.639s\n",
      "[627/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50220, val loss: 0.53939, in 3.053s\n",
      "[628/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50210, val loss: 0.53935, in 8.781s\n",
      "[629/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50200, val loss: 0.53931, in 4.271s\n",
      "[630/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50192, val loss: 0.53928, in 4.619s\n",
      "[631/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50181, val loss: 0.53922, in 5.122s\n",
      "[632/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50172, val loss: 0.53918, in 4.335s\n",
      "[633/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50161, val loss: 0.53915, in 3.373s\n",
      "[634/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50152, val loss: 0.53910, in 3.413s\n",
      "[635/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50143, val loss: 0.53906, in 5.663s\n",
      "[636/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50131, val loss: 0.53897, in 3.185s\n",
      "[637/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50122, val loss: 0.53893, in 2.757s\n",
      "[638/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50113, val loss: 0.53888, in 2.477s\n",
      "[639/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50103, val loss: 0.53883, in 2.279s\n",
      "[640/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50093, val loss: 0.53879, in 2.665s\n",
      "[641/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50083, val loss: 0.53874, in 3.918s\n",
      "[642/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50073, val loss: 0.53868, in 7.430s\n",
      "[643/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50063, val loss: 0.53863, in 4.594s\n",
      "[644/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.50054, val loss: 0.53859, in 3.023s\n",
      "[645/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.50044, val loss: 0.53853, in 2.514s\n",
      "[646/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50033, val loss: 0.53848, in 3.473s\n",
      "[647/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.50022, val loss: 0.53843, in 2.866s\n",
      "[648/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.50012, val loss: 0.53839, in 2.362s\n",
      "[649/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.50003, val loss: 0.53834, in 2.446s\n",
      "[650/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49992, val loss: 0.53830, in 2.452s\n",
      "[651/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49984, val loss: 0.53825, in 2.613s\n",
      "[652/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49975, val loss: 0.53822, in 2.402s\n",
      "[653/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49965, val loss: 0.53817, in 2.297s\n",
      "[654/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49956, val loss: 0.53811, in 2.303s\n",
      "[655/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.49946, val loss: 0.53808, in 2.402s\n",
      "[656/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49950, val loss: 0.53820, in 2.386s\n",
      "[657/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49936, val loss: 0.53808, in 2.673s\n",
      "[658/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.49927, val loss: 0.53804, in 2.453s\n",
      "[659/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.49914, val loss: 0.53798, in 3.170s\n",
      "[660/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49905, val loss: 0.53795, in 2.391s\n",
      "[661/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49895, val loss: 0.53791, in 2.469s\n",
      "[662/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49887, val loss: 0.53786, in 2.223s\n",
      "[663/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49875, val loss: 0.53778, in 2.282s\n",
      "[664/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49864, val loss: 0.53772, in 2.470s\n",
      "[665/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49855, val loss: 0.53767, in 2.231s\n",
      "[666/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.49846, val loss: 0.53762, in 2.275s\n",
      "[667/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49835, val loss: 0.53756, in 2.307s\n",
      "[668/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49825, val loss: 0.53750, in 2.370s\n",
      "[669/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.49817, val loss: 0.53748, in 2.267s\n",
      "[670/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49808, val loss: 0.53744, in 2.422s\n",
      "[671/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.49798, val loss: 0.53739, in 2.205s\n",
      "[672/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49790, val loss: 0.53735, in 2.182s\n",
      "[673/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.49780, val loss: 0.53729, in 2.676s\n",
      "[674/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.49772, val loss: 0.53726, in 2.044s\n",
      "[675/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49763, val loss: 0.53724, in 2.352s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[676/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49754, val loss: 0.53718, in 2.142s\n",
      "[677/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49744, val loss: 0.53714, in 2.353s\n",
      "[678/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49734, val loss: 0.53709, in 2.559s\n",
      "[679/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49723, val loss: 0.53702, in 2.506s\n",
      "[680/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49712, val loss: 0.53696, in 2.713s\n",
      "[681/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49702, val loss: 0.53692, in 2.254s\n",
      "[682/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49691, val loss: 0.53685, in 2.656s\n",
      "[683/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49680, val loss: 0.53680, in 2.269s\n",
      "[684/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49669, val loss: 0.53674, in 2.351s\n",
      "[685/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49660, val loss: 0.53672, in 2.275s\n",
      "[686/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49651, val loss: 0.53668, in 2.367s\n",
      "[687/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49642, val loss: 0.53664, in 2.488s\n",
      "[688/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49634, val loss: 0.53660, in 2.274s\n",
      "[689/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49625, val loss: 0.53656, in 2.282s\n",
      "[690/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49615, val loss: 0.53650, in 2.189s\n",
      "[691/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49604, val loss: 0.53647, in 2.320s\n",
      "[692/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.49595, val loss: 0.53642, in 2.227s\n",
      "[693/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.49585, val loss: 0.53639, in 2.191s\n",
      "[694/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49576, val loss: 0.53636, in 2.539s\n",
      "[695/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.49567, val loss: 0.53633, in 2.169s\n",
      "[696/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49558, val loss: 0.53628, in 2.399s\n",
      "[697/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49547, val loss: 0.53622, in 2.387s\n",
      "[698/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49535, val loss: 0.53618, in 2.366s\n",
      "[699/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49526, val loss: 0.53615, in 2.380s\n",
      "[700/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49519, val loss: 0.53613, in 2.268s\n",
      "[701/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49510, val loss: 0.53610, in 2.482s\n",
      "[702/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49498, val loss: 0.53603, in 2.565s\n",
      "[703/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49488, val loss: 0.53598, in 2.279s\n",
      "[704/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49477, val loss: 0.53590, in 2.464s\n",
      "[705/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49470, val loss: 0.53589, in 2.428s\n",
      "[706/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49462, val loss: 0.53586, in 2.331s\n",
      "[707/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49453, val loss: 0.53584, in 2.302s\n",
      "[708/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49444, val loss: 0.53579, in 2.309s\n",
      "[709/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49435, val loss: 0.53574, in 2.312s\n",
      "[710/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49427, val loss: 0.53570, in 2.249s\n",
      "[711/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49417, val loss: 0.53563, in 2.312s\n",
      "[712/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49408, val loss: 0.53559, in 2.398s\n",
      "[713/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49399, val loss: 0.53554, in 2.272s\n",
      "[714/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.49390, val loss: 0.53549, in 2.460s\n",
      "[715/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49381, val loss: 0.53546, in 2.343s\n",
      "[716/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49373, val loss: 0.53544, in 2.246s\n",
      "[717/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49365, val loss: 0.53541, in 2.480s\n",
      "[718/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49353, val loss: 0.53535, in 2.233s\n",
      "[719/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49344, val loss: 0.53531, in 2.396s\n",
      "[720/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.49334, val loss: 0.53527, in 2.501s\n",
      "[721/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49326, val loss: 0.53525, in 2.312s\n",
      "[722/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49318, val loss: 0.53520, in 2.139s\n",
      "[723/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49308, val loss: 0.53515, in 3.796s\n",
      "[724/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49300, val loss: 0.53511, in 2.212s\n",
      "[725/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49291, val loss: 0.53507, in 2.468s\n",
      "[726/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49284, val loss: 0.53504, in 2.063s\n",
      "[727/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49276, val loss: 0.53501, in 2.351s\n",
      "[728/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49266, val loss: 0.53498, in 2.191s\n",
      "[729/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49257, val loss: 0.53492, in 2.119s\n",
      "[730/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49250, val loss: 0.53490, in 1.989s\n",
      "[731/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49242, val loss: 0.53487, in 2.111s\n",
      "[732/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49232, val loss: 0.53482, in 2.590s\n",
      "[733/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49223, val loss: 0.53478, in 2.317s\n",
      "[734/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49214, val loss: 0.53475, in 2.556s\n",
      "[735/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49206, val loss: 0.53471, in 2.332s\n",
      "[736/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49198, val loss: 0.53468, in 2.302s\n",
      "[737/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49189, val loss: 0.53465, in 3.096s\n",
      "[738/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49180, val loss: 0.53461, in 2.166s\n",
      "[739/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49172, val loss: 0.53456, in 2.384s\n",
      "[740/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49164, val loss: 0.53453, in 2.355s\n",
      "[741/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49155, val loss: 0.53450, in 2.321s\n",
      "[742/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49145, val loss: 0.53445, in 2.207s\n",
      "[743/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.49135, val loss: 0.53439, in 2.307s\n",
      "[744/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49127, val loss: 0.53435, in 2.343s\n",
      "[745/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49119, val loss: 0.53432, in 2.619s\n",
      "[746/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49110, val loss: 0.53429, in 2.454s\n",
      "[747/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49101, val loss: 0.53424, in 2.497s\n",
      "[748/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49091, val loss: 0.53419, in 2.506s\n",
      "[749/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49084, val loss: 0.53416, in 2.225s\n",
      "[750/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49076, val loss: 0.53413, in 2.274s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[751/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49068, val loss: 0.53409, in 2.094s\n",
      "[752/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.49060, val loss: 0.53406, in 2.420s\n",
      "[753/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49051, val loss: 0.53404, in 2.280s\n",
      "[754/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49041, val loss: 0.53398, in 2.476s\n",
      "[755/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.49033, val loss: 0.53394, in 2.197s\n",
      "[756/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49025, val loss: 0.53391, in 2.487s\n",
      "[757/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.49016, val loss: 0.53387, in 2.360s\n",
      "[758/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49009, val loss: 0.53385, in 1.959s\n",
      "[759/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.49002, val loss: 0.53383, in 2.199s\n",
      "[760/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48993, val loss: 0.53378, in 5.157s\n",
      "[761/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48986, val loss: 0.53377, in 2.059s\n",
      "[762/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.48976, val loss: 0.53371, in 2.937s\n",
      "[763/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48967, val loss: 0.53367, in 2.296s\n",
      "[764/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48959, val loss: 0.53364, in 2.228s\n",
      "[765/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48951, val loss: 0.53361, in 2.546s\n",
      "[766/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48943, val loss: 0.53359, in 2.297s\n",
      "[767/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48935, val loss: 0.53354, in 2.131s\n",
      "[768/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.48927, val loss: 0.53352, in 2.205s\n",
      "[769/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48920, val loss: 0.53349, in 2.167s\n",
      "[770/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48913, val loss: 0.53346, in 2.196s\n",
      "[771/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48903, val loss: 0.53342, in 2.282s\n",
      "[772/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.48895, val loss: 0.53337, in 2.326s\n",
      "[773/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48884, val loss: 0.53333, in 2.390s\n",
      "[774/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48874, val loss: 0.53329, in 2.155s\n",
      "[775/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48866, val loss: 0.53326, in 2.132s\n",
      "[776/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48857, val loss: 0.53322, in 2.222s\n",
      "[777/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48848, val loss: 0.53319, in 2.416s\n",
      "[778/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48840, val loss: 0.53316, in 2.377s\n",
      "[779/5000] 7 trees, 217 leaves (31 on avg), max depth = 21, train loss: 0.48828, val loss: 0.53311, in 2.387s\n",
      "[780/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48819, val loss: 0.53306, in 2.461s\n",
      "[781/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48811, val loss: 0.53304, in 2.477s\n",
      "[782/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48804, val loss: 0.53300, in 2.109s\n",
      "[783/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48795, val loss: 0.53297, in 2.499s\n",
      "[784/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48787, val loss: 0.53294, in 2.626s\n",
      "[785/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48779, val loss: 0.53290, in 3.455s\n",
      "[786/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48767, val loss: 0.53284, in 3.846s\n",
      "[787/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48760, val loss: 0.53281, in 3.480s\n",
      "[788/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48751, val loss: 0.53277, in 2.905s\n",
      "[789/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48742, val loss: 0.53272, in 2.043s\n",
      "[790/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48734, val loss: 0.53268, in 2.267s\n",
      "[791/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48725, val loss: 0.53263, in 2.630s\n",
      "[792/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48716, val loss: 0.53258, in 2.116s\n",
      "[793/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48708, val loss: 0.53254, in 2.322s\n",
      "[794/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48701, val loss: 0.53253, in 2.240s\n",
      "[795/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48691, val loss: 0.53247, in 2.485s\n",
      "[796/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48684, val loss: 0.53244, in 2.270s\n",
      "[797/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48676, val loss: 0.53242, in 2.075s\n",
      "[798/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.48667, val loss: 0.53237, in 2.274s\n",
      "[799/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.48660, val loss: 0.53235, in 2.158s\n",
      "[800/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48652, val loss: 0.53233, in 2.181s\n",
      "[801/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48644, val loss: 0.53229, in 2.140s\n",
      "[802/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48637, val loss: 0.53225, in 2.208s\n",
      "[803/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48626, val loss: 0.53220, in 2.335s\n",
      "[804/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48618, val loss: 0.53217, in 2.122s\n",
      "[805/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48610, val loss: 0.53212, in 2.239s\n",
      "[806/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48603, val loss: 0.53210, in 2.021s\n",
      "[807/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48595, val loss: 0.53207, in 2.276s\n",
      "[808/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48588, val loss: 0.53204, in 2.137s\n",
      "[809/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48579, val loss: 0.53200, in 2.266s\n",
      "[810/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48568, val loss: 0.53193, in 2.441s\n",
      "[811/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48558, val loss: 0.53188, in 2.546s\n",
      "[812/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48549, val loss: 0.53186, in 2.178s\n",
      "[813/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.48542, val loss: 0.53184, in 2.279s\n",
      "[814/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48532, val loss: 0.53179, in 2.359s\n",
      "[815/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48523, val loss: 0.53177, in 2.233s\n",
      "[816/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48515, val loss: 0.53173, in 2.332s\n",
      "[817/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.48507, val loss: 0.53168, in 2.342s\n",
      "[818/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48500, val loss: 0.53165, in 2.426s\n",
      "[819/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48493, val loss: 0.53160, in 1.958s\n",
      "[820/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48485, val loss: 0.53158, in 2.040s\n",
      "[821/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48478, val loss: 0.53154, in 2.328s\n",
      "[822/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48470, val loss: 0.53151, in 2.434s\n",
      "[823/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48463, val loss: 0.53148, in 2.101s\n",
      "[824/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48456, val loss: 0.53145, in 2.237s\n",
      "[825/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48449, val loss: 0.53143, in 2.244s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[826/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48440, val loss: 0.53140, in 2.296s\n",
      "[827/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48433, val loss: 0.53137, in 2.325s\n",
      "[828/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48425, val loss: 0.53134, in 2.199s\n",
      "[829/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48416, val loss: 0.53130, in 2.465s\n",
      "[830/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48408, val loss: 0.53128, in 2.335s\n",
      "[831/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48401, val loss: 0.53125, in 2.315s\n",
      "[832/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48395, val loss: 0.53124, in 2.033s\n",
      "[833/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48389, val loss: 0.53122, in 2.048s\n",
      "[834/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48381, val loss: 0.53118, in 2.204s\n",
      "[835/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48372, val loss: 0.53115, in 2.408s\n",
      "[836/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48364, val loss: 0.53111, in 2.228s\n",
      "[837/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48357, val loss: 0.53108, in 2.157s\n",
      "[838/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48348, val loss: 0.53103, in 2.347s\n",
      "[839/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48341, val loss: 0.53100, in 2.371s\n",
      "[840/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48333, val loss: 0.53097, in 2.147s\n",
      "[841/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48326, val loss: 0.53095, in 2.514s\n",
      "[842/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48320, val loss: 0.53093, in 2.527s\n",
      "[843/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48313, val loss: 0.53092, in 3.120s\n",
      "[844/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48306, val loss: 0.53090, in 2.244s\n",
      "[845/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48299, val loss: 0.53086, in 3.092s\n",
      "[846/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48291, val loss: 0.53083, in 3.074s\n",
      "[847/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48283, val loss: 0.53080, in 2.576s\n",
      "[848/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.48277, val loss: 0.53077, in 2.223s\n",
      "[849/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48270, val loss: 0.53076, in 1.969s\n",
      "[850/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48263, val loss: 0.53072, in 2.260s\n",
      "[851/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.48254, val loss: 0.53068, in 2.335s\n",
      "[852/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48246, val loss: 0.53066, in 2.422s\n",
      "[853/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48235, val loss: 0.53060, in 2.472s\n",
      "[854/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48227, val loss: 0.53057, in 2.275s\n",
      "[855/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48219, val loss: 0.53054, in 2.168s\n",
      "[856/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48211, val loss: 0.53052, in 2.404s\n",
      "[857/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48203, val loss: 0.53049, in 2.282s\n",
      "[858/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48194, val loss: 0.53044, in 2.422s\n",
      "[859/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48185, val loss: 0.53040, in 2.275s\n",
      "[860/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.48176, val loss: 0.53036, in 2.444s\n",
      "[861/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48169, val loss: 0.53035, in 2.266s\n",
      "[862/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48163, val loss: 0.53034, in 2.051s\n",
      "[863/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.48155, val loss: 0.53032, in 2.440s\n",
      "[864/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48146, val loss: 0.53027, in 2.515s\n",
      "[865/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48138, val loss: 0.53023, in 2.282s\n",
      "[866/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48129, val loss: 0.53018, in 2.421s\n",
      "[867/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.48123, val loss: 0.53016, in 2.055s\n",
      "[868/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48116, val loss: 0.53013, in 2.207s\n",
      "[869/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48108, val loss: 0.53008, in 2.526s\n",
      "[870/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.48100, val loss: 0.53006, in 2.255s\n",
      "[871/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48090, val loss: 0.53001, in 2.281s\n",
      "[872/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48082, val loss: 0.52998, in 2.122s\n",
      "[873/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.48073, val loss: 0.52996, in 2.344s\n",
      "[874/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48066, val loss: 0.52994, in 2.246s\n",
      "[875/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48057, val loss: 0.52991, in 2.088s\n",
      "[876/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.48050, val loss: 0.52987, in 2.809s\n",
      "[877/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48044, val loss: 0.52985, in 2.551s\n",
      "[878/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48037, val loss: 0.52980, in 2.255s\n",
      "[879/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.48030, val loss: 0.52978, in 2.130s\n",
      "[880/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.48021, val loss: 0.52973, in 2.526s\n",
      "[881/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.48014, val loss: 0.52970, in 2.131s\n",
      "[882/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.48007, val loss: 0.52967, in 2.454s\n",
      "[883/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47998, val loss: 0.52963, in 2.361s\n",
      "[884/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47991, val loss: 0.52960, in 2.216s\n",
      "[885/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47984, val loss: 0.52959, in 2.175s\n",
      "[886/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47977, val loss: 0.52955, in 2.227s\n",
      "[887/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47969, val loss: 0.52953, in 2.276s\n",
      "[888/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47964, val loss: 0.52951, in 2.177s\n",
      "[889/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47957, val loss: 0.52948, in 2.419s\n",
      "[890/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47950, val loss: 0.52947, in 2.433s\n",
      "[891/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47944, val loss: 0.52945, in 2.100s\n",
      "[892/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47937, val loss: 0.52941, in 2.189s\n",
      "[893/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.47931, val loss: 0.52938, in 1.889s\n",
      "[894/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47923, val loss: 0.52936, in 2.520s\n",
      "[895/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47916, val loss: 0.52934, in 2.006s\n",
      "[896/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47908, val loss: 0.52930, in 2.487s\n",
      "[897/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47900, val loss: 0.52925, in 2.355s\n",
      "[898/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47892, val loss: 0.52922, in 2.207s\n",
      "[899/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47884, val loss: 0.52918, in 2.448s\n",
      "[900/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47876, val loss: 0.52915, in 2.205s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[901/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47869, val loss: 0.52911, in 2.215s\n",
      "[902/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.47862, val loss: 0.52909, in 2.068s\n",
      "[903/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47854, val loss: 0.52905, in 2.206s\n",
      "[904/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47847, val loss: 0.52904, in 2.205s\n",
      "[905/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.47841, val loss: 0.52902, in 2.394s\n",
      "[906/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47833, val loss: 0.52897, in 2.146s\n",
      "[907/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.47826, val loss: 0.52895, in 2.125s\n",
      "[908/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47819, val loss: 0.52893, in 2.205s\n",
      "[909/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47812, val loss: 0.52890, in 2.161s\n",
      "[910/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47803, val loss: 0.52887, in 2.393s\n",
      "[911/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47796, val loss: 0.52885, in 2.147s\n",
      "[912/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47789, val loss: 0.52883, in 2.234s\n",
      "[913/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47783, val loss: 0.52880, in 1.989s\n",
      "[914/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47775, val loss: 0.52878, in 2.239s\n",
      "[915/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47769, val loss: 0.52876, in 2.101s\n",
      "[916/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47762, val loss: 0.52874, in 2.406s\n",
      "[917/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.47754, val loss: 0.52872, in 2.446s\n",
      "[918/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47747, val loss: 0.52870, in 2.282s\n",
      "[919/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47739, val loss: 0.52865, in 2.215s\n",
      "[920/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47733, val loss: 0.52864, in 1.812s\n",
      "[921/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47726, val loss: 0.52860, in 2.029s\n",
      "[922/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47719, val loss: 0.52860, in 2.239s\n",
      "[923/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47712, val loss: 0.52858, in 2.181s\n",
      "[924/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47704, val loss: 0.52854, in 2.385s\n",
      "[925/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47697, val loss: 0.52851, in 2.199s\n",
      "[926/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47689, val loss: 0.52848, in 2.221s\n",
      "[927/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47683, val loss: 0.52846, in 2.228s\n",
      "[928/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47676, val loss: 0.52843, in 2.131s\n",
      "[929/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47668, val loss: 0.52839, in 2.336s\n",
      "[930/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47662, val loss: 0.52838, in 2.124s\n",
      "[931/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47655, val loss: 0.52835, in 2.140s\n",
      "[932/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47647, val loss: 0.52832, in 2.183s\n",
      "[933/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47641, val loss: 0.52831, in 2.178s\n",
      "[934/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47633, val loss: 0.52828, in 2.397s\n",
      "[935/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47626, val loss: 0.52825, in 2.156s\n",
      "[936/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47620, val loss: 0.52823, in 2.208s\n",
      "[937/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47614, val loss: 0.52821, in 2.189s\n",
      "[938/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47607, val loss: 0.52820, in 2.344s\n",
      "[939/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47598, val loss: 0.52815, in 2.367s\n",
      "[940/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47590, val loss: 0.52813, in 2.513s\n",
      "[941/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47583, val loss: 0.52811, in 2.197s\n",
      "[942/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47575, val loss: 0.52810, in 2.242s\n",
      "[943/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47568, val loss: 0.52807, in 2.182s\n",
      "[944/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47561, val loss: 0.52804, in 2.127s\n",
      "[945/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47554, val loss: 0.52804, in 3.674s\n",
      "[946/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47548, val loss: 0.52801, in 4.284s\n",
      "[947/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47542, val loss: 0.52799, in 9.245s\n",
      "[948/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47533, val loss: 0.52794, in 2.626s\n",
      "[949/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.47524, val loss: 0.52790, in 2.615s\n",
      "[950/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47518, val loss: 0.52789, in 2.412s\n",
      "[951/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47512, val loss: 0.52788, in 2.701s\n",
      "[952/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47505, val loss: 0.52786, in 2.195s\n",
      "[953/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47498, val loss: 0.52782, in 2.530s\n",
      "[954/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47491, val loss: 0.52780, in 2.126s\n",
      "[955/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47485, val loss: 0.52778, in 2.180s\n",
      "[956/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47479, val loss: 0.52776, in 2.397s\n",
      "[957/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47470, val loss: 0.52773, in 2.689s\n",
      "[958/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47464, val loss: 0.52772, in 2.543s\n",
      "[959/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47458, val loss: 0.52770, in 1.972s\n",
      "[960/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47451, val loss: 0.52767, in 1.939s\n",
      "[961/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47445, val loss: 0.52765, in 2.068s\n",
      "[962/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47440, val loss: 0.52763, in 2.221s\n",
      "[963/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.47433, val loss: 0.52760, in 2.117s\n",
      "[964/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47426, val loss: 0.52757, in 2.259s\n",
      "[965/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47419, val loss: 0.52755, in 2.908s\n",
      "[966/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47411, val loss: 0.52752, in 2.205s\n",
      "[967/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47405, val loss: 0.52750, in 1.781s\n",
      "[968/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47398, val loss: 0.52747, in 2.261s\n",
      "[969/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47392, val loss: 0.52744, in 2.282s\n",
      "[970/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47385, val loss: 0.52741, in 2.159s\n",
      "[971/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47379, val loss: 0.52740, in 2.210s\n",
      "[972/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47370, val loss: 0.52736, in 2.294s\n",
      "[973/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47364, val loss: 0.52733, in 2.261s\n",
      "[974/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47356, val loss: 0.52731, in 2.227s\n",
      "[975/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47349, val loss: 0.52727, in 2.112s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[976/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47341, val loss: 0.52723, in 2.348s\n",
      "[977/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47334, val loss: 0.52722, in 2.378s\n",
      "[978/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47329, val loss: 0.52720, in 2.179s\n",
      "[979/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47322, val loss: 0.52718, in 2.380s\n",
      "[980/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.47316, val loss: 0.52716, in 2.158s\n",
      "[981/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47310, val loss: 0.52713, in 2.204s\n",
      "[982/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47301, val loss: 0.52710, in 2.461s\n",
      "[983/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47294, val loss: 0.52707, in 2.165s\n",
      "[984/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47287, val loss: 0.52703, in 2.331s\n",
      "[985/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.47280, val loss: 0.52702, in 2.032s\n",
      "[986/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47273, val loss: 0.52700, in 2.110s\n",
      "[987/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47267, val loss: 0.52698, in 2.023s\n",
      "[988/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47260, val loss: 0.52695, in 2.318s\n",
      "[989/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47254, val loss: 0.52694, in 2.197s\n",
      "[990/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.47248, val loss: 0.52691, in 2.222s\n",
      "[991/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47241, val loss: 0.52688, in 2.484s\n",
      "[992/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47234, val loss: 0.52685, in 2.390s\n",
      "[993/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47226, val loss: 0.52680, in 2.438s\n",
      "[994/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47219, val loss: 0.52679, in 2.296s\n",
      "[995/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47214, val loss: 0.52678, in 2.109s\n",
      "[996/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47206, val loss: 0.52676, in 2.402s\n",
      "[997/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47199, val loss: 0.52673, in 2.138s\n",
      "[998/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.47193, val loss: 0.52671, in 2.151s\n",
      "[999/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47186, val loss: 0.52669, in 2.143s\n",
      "[1000/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47180, val loss: 0.52667, in 2.296s\n",
      "[1001/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47174, val loss: 0.52666, in 2.383s\n",
      "[1002/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47166, val loss: 0.52662, in 2.719s\n",
      "[1003/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.47159, val loss: 0.52659, in 2.427s\n",
      "[1004/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47153, val loss: 0.52659, in 2.304s\n",
      "[1005/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.47146, val loss: 0.52656, in 2.314s\n",
      "[1006/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47139, val loss: 0.52655, in 2.141s\n",
      "[1007/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47133, val loss: 0.52653, in 1.995s\n",
      "[1008/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47128, val loss: 0.52651, in 1.908s\n",
      "[1009/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.47121, val loss: 0.52649, in 2.235s\n",
      "[1010/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47116, val loss: 0.52648, in 2.215s\n",
      "[1011/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47110, val loss: 0.52646, in 2.102s\n",
      "[1012/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47104, val loss: 0.52644, in 2.361s\n",
      "[1013/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47097, val loss: 0.52642, in 2.285s\n",
      "[1014/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47090, val loss: 0.52641, in 2.517s\n",
      "[1015/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47082, val loss: 0.52639, in 2.422s\n",
      "[1016/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47077, val loss: 0.52640, in 2.082s\n",
      "[1017/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47071, val loss: 0.52638, in 2.374s\n",
      "[1018/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47065, val loss: 0.52636, in 2.285s\n",
      "[1019/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47060, val loss: 0.52635, in 2.104s\n",
      "[1020/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.47052, val loss: 0.52633, in 2.080s\n",
      "[1021/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.47045, val loss: 0.52631, in 2.228s\n",
      "[1022/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47039, val loss: 0.52629, in 2.200s\n",
      "[1023/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.47032, val loss: 0.52625, in 2.254s\n",
      "[1024/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47026, val loss: 0.52624, in 2.228s\n",
      "[1025/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.47021, val loss: 0.52624, in 2.188s\n",
      "[1026/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.47015, val loss: 0.52623, in 2.150s\n",
      "[1027/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.47008, val loss: 0.52620, in 2.199s\n",
      "[1028/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.47003, val loss: 0.52620, in 2.372s\n",
      "[1029/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.46997, val loss: 0.52618, in 2.527s\n",
      "[1030/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.46990, val loss: 0.52617, in 1.980s\n",
      "[1031/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46984, val loss: 0.52614, in 2.002s\n",
      "[1032/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46978, val loss: 0.52613, in 1.966s\n",
      "[1033/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46972, val loss: 0.52612, in 2.133s\n",
      "[1034/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46965, val loss: 0.52609, in 1.873s\n",
      "[1035/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46957, val loss: 0.52607, in 2.320s\n",
      "[1036/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46952, val loss: 0.52606, in 2.003s\n",
      "[1037/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.46945, val loss: 0.52603, in 2.125s\n",
      "[1038/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.46938, val loss: 0.52600, in 2.162s\n",
      "[1039/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.46932, val loss: 0.52599, in 1.959s\n",
      "[1040/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46926, val loss: 0.52598, in 2.529s\n",
      "[1041/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46919, val loss: 0.52594, in 2.154s\n",
      "[1042/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46913, val loss: 0.52592, in 2.045s\n",
      "[1043/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.46907, val loss: 0.52591, in 2.067s\n",
      "[1044/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46900, val loss: 0.52588, in 2.051s\n",
      "[1045/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46894, val loss: 0.52586, in 2.261s\n",
      "[1046/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.46887, val loss: 0.52584, in 2.356s\n",
      "[1047/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.46879, val loss: 0.52580, in 2.367s\n",
      "[1048/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46871, val loss: 0.52577, in 2.484s\n",
      "[1049/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46864, val loss: 0.52576, in 2.111s\n",
      "[1050/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46858, val loss: 0.52575, in 2.021s\n",
      "[1051/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46853, val loss: 0.52574, in 2.094s\n",
      "[1052/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46847, val loss: 0.52571, in 2.169s\n",
      "[1053/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46840, val loss: 0.52570, in 2.266s\n",
      "[1054/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46833, val loss: 0.52569, in 2.186s\n",
      "[1055/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46827, val loss: 0.52565, in 2.258s\n",
      "[1056/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46820, val loss: 0.52563, in 2.257s\n",
      "[1057/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.46813, val loss: 0.52561, in 2.093s\n",
      "[1058/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46808, val loss: 0.52560, in 1.889s\n",
      "[1059/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46803, val loss: 0.52558, in 1.986s\n",
      "[1060/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46796, val loss: 0.52557, in 2.256s\n",
      "[1061/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46791, val loss: 0.52556, in 2.287s\n",
      "[1062/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46785, val loss: 0.52555, in 2.387s\n",
      "[1063/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46779, val loss: 0.52553, in 2.120s\n",
      "[1064/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46774, val loss: 0.52551, in 2.327s\n",
      "[1065/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46768, val loss: 0.52550, in 2.099s\n",
      "[1066/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46760, val loss: 0.52549, in 2.471s\n",
      "[1067/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46755, val loss: 0.52548, in 1.991s\n",
      "[1068/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46749, val loss: 0.52546, in 2.342s\n",
      "[1069/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.46744, val loss: 0.52546, in 2.174s\n",
      "[1070/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46738, val loss: 0.52545, in 2.202s\n",
      "[1071/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46733, val loss: 0.52543, in 2.098s\n",
      "[1072/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46727, val loss: 0.52541, in 2.169s\n",
      "[1073/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46721, val loss: 0.52538, in 2.157s\n",
      "[1074/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46712, val loss: 0.52533, in 2.433s\n",
      "[1075/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46705, val loss: 0.52532, in 2.543s\n",
      "[1076/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.46700, val loss: 0.52531, in 1.902s\n",
      "[1077/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.46694, val loss: 0.52528, in 2.354s\n",
      "[1078/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46688, val loss: 0.52526, in 2.269s\n",
      "[1079/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46682, val loss: 0.52525, in 2.215s\n",
      "[1080/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46675, val loss: 0.52522, in 2.085s\n",
      "[1081/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46669, val loss: 0.52521, in 1.949s\n",
      "[1082/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46660, val loss: 0.52517, in 2.223s\n",
      "[1083/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46655, val loss: 0.52516, in 2.221s\n",
      "[1084/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46648, val loss: 0.52512, in 2.215s\n",
      "[1085/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46642, val loss: 0.52511, in 2.138s\n",
      "[1086/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46637, val loss: 0.52511, in 2.168s\n",
      "[1087/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46631, val loss: 0.52510, in 2.456s\n",
      "[1088/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.46625, val loss: 0.52510, in 2.104s\n",
      "[1089/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46620, val loss: 0.52508, in 2.231s\n",
      "[1090/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46613, val loss: 0.52506, in 2.346s\n",
      "[1091/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46608, val loss: 0.52506, in 2.064s\n",
      "[1092/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.46603, val loss: 0.52505, in 2.163s\n",
      "[1093/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46595, val loss: 0.52502, in 2.237s\n",
      "[1094/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46589, val loss: 0.52500, in 2.388s\n",
      "[1095/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46581, val loss: 0.52495, in 2.379s\n",
      "[1096/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46574, val loss: 0.52493, in 2.352s\n",
      "[1097/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46568, val loss: 0.52490, in 2.242s\n",
      "[1098/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46561, val loss: 0.52487, in 1.996s\n",
      "[1099/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46554, val loss: 0.52485, in 2.268s\n",
      "[1100/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46548, val loss: 0.52483, in 2.261s\n",
      "[1101/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46542, val loss: 0.52481, in 2.297s\n",
      "[1102/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46535, val loss: 0.52478, in 2.242s\n",
      "[1103/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46528, val loss: 0.52476, in 2.063s\n",
      "[1104/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46522, val loss: 0.52474, in 2.132s\n",
      "[1105/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.46515, val loss: 0.52472, in 2.385s\n",
      "[1106/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.46509, val loss: 0.52470, in 2.105s\n",
      "[1107/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46501, val loss: 0.52468, in 1.986s\n",
      "[1108/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46495, val loss: 0.52465, in 2.368s\n",
      "[1109/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46490, val loss: 0.52464, in 2.055s\n",
      "[1110/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.46484, val loss: 0.52464, in 2.077s\n",
      "[1111/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46476, val loss: 0.52461, in 2.197s\n",
      "[1112/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46471, val loss: 0.52459, in 2.009s\n",
      "[1113/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46466, val loss: 0.52458, in 2.064s\n",
      "[1114/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.46461, val loss: 0.52457, in 2.248s\n",
      "[1115/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46454, val loss: 0.52455, in 2.282s\n",
      "[1116/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46448, val loss: 0.52452, in 1.845s\n",
      "[1117/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46442, val loss: 0.52450, in 2.026s\n",
      "[1118/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46436, val loss: 0.52449, in 2.103s\n",
      "[1119/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46431, val loss: 0.52447, in 2.339s\n",
      "[1120/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.46425, val loss: 0.52445, in 2.176s\n",
      "[1121/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46418, val loss: 0.52443, in 2.282s\n",
      "[1122/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46410, val loss: 0.52440, in 2.431s\n",
      "[1123/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46401, val loss: 0.52436, in 2.216s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1124/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46395, val loss: 0.52433, in 2.482s\n",
      "[1125/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46389, val loss: 0.52432, in 2.427s\n",
      "[1126/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.46382, val loss: 0.52430, in 2.561s\n",
      "[1127/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46376, val loss: 0.52429, in 2.307s\n",
      "[1128/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46371, val loss: 0.52427, in 2.275s\n",
      "[1129/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46365, val loss: 0.52426, in 2.116s\n",
      "[1130/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.46359, val loss: 0.52424, in 2.292s\n",
      "[1131/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.46354, val loss: 0.52423, in 1.970s\n",
      "[1132/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46347, val loss: 0.52421, in 2.206s\n",
      "[1133/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46341, val loss: 0.52419, in 2.157s\n",
      "[1134/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46335, val loss: 0.52418, in 2.344s\n",
      "[1135/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46330, val loss: 0.52417, in 2.007s\n",
      "[1136/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46324, val loss: 0.52416, in 2.404s\n",
      "[1137/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46318, val loss: 0.52414, in 2.392s\n",
      "[1138/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46314, val loss: 0.52413, in 1.907s\n",
      "[1139/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46308, val loss: 0.52413, in 2.267s\n",
      "[1140/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46302, val loss: 0.52411, in 2.009s\n",
      "[1141/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46296, val loss: 0.52408, in 1.992s\n",
      "[1142/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46291, val loss: 0.52406, in 2.166s\n",
      "[1143/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46284, val loss: 0.52404, in 2.173s\n",
      "[1144/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.46277, val loss: 0.52400, in 2.274s\n",
      "[1145/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46272, val loss: 0.52398, in 2.042s\n",
      "[1146/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46267, val loss: 0.52396, in 2.179s\n",
      "[1147/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46262, val loss: 0.52396, in 1.956s\n",
      "[1148/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46256, val loss: 0.52393, in 2.372s\n",
      "[1149/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46250, val loss: 0.52392, in 2.208s\n",
      "[1150/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.46244, val loss: 0.52391, in 2.187s\n",
      "[1151/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46238, val loss: 0.52390, in 2.105s\n",
      "[1152/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46232, val loss: 0.52389, in 2.085s\n",
      "[1153/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46226, val loss: 0.52387, in 2.471s\n",
      "[1154/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46220, val loss: 0.52385, in 2.141s\n",
      "[1155/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.46216, val loss: 0.52385, in 2.208s\n",
      "[1156/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46209, val loss: 0.52385, in 2.542s\n",
      "[1157/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46204, val loss: 0.52383, in 1.939s\n",
      "[1158/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46198, val loss: 0.52382, in 2.086s\n",
      "[1159/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46192, val loss: 0.52379, in 2.247s\n",
      "[1160/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46186, val loss: 0.52377, in 2.184s\n",
      "[1161/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46180, val loss: 0.52376, in 2.199s\n",
      "[1162/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46174, val loss: 0.52374, in 2.023s\n",
      "[1163/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46169, val loss: 0.52373, in 1.707s\n",
      "[1164/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46165, val loss: 0.52373, in 1.958s\n",
      "[1165/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46159, val loss: 0.52371, in 2.177s\n",
      "[1166/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46151, val loss: 0.52368, in 2.400s\n",
      "[1167/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46145, val loss: 0.52366, in 2.496s\n",
      "[1168/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46137, val loss: 0.52362, in 2.301s\n",
      "[1169/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46131, val loss: 0.52362, in 2.177s\n",
      "[1170/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46126, val loss: 0.52360, in 2.142s\n",
      "[1171/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46120, val loss: 0.52358, in 2.261s\n",
      "[1172/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46113, val loss: 0.52355, in 2.290s\n",
      "[1173/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46108, val loss: 0.52355, in 2.082s\n",
      "[1174/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46103, val loss: 0.52353, in 2.136s\n",
      "[1175/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46099, val loss: 0.52352, in 1.842s\n",
      "[1176/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46093, val loss: 0.52349, in 2.067s\n",
      "[1177/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46087, val loss: 0.52347, in 2.133s\n",
      "[1178/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.46081, val loss: 0.52346, in 2.116s\n",
      "[1179/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46076, val loss: 0.52345, in 2.147s\n",
      "[1180/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46070, val loss: 0.52343, in 2.191s\n",
      "[1181/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46064, val loss: 0.52341, in 2.200s\n",
      "[1182/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46058, val loss: 0.52339, in 2.037s\n",
      "[1183/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46051, val loss: 0.52335, in 2.429s\n",
      "[1184/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46046, val loss: 0.52335, in 1.996s\n",
      "[1185/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.46040, val loss: 0.52332, in 2.107s\n",
      "[1186/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.46034, val loss: 0.52331, in 2.105s\n",
      "[1187/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.46028, val loss: 0.52329, in 1.924s\n",
      "[1188/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.46022, val loss: 0.52327, in 2.364s\n",
      "[1189/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46017, val loss: 0.52327, in 2.084s\n",
      "[1190/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46012, val loss: 0.52327, in 2.266s\n",
      "[1191/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.46005, val loss: 0.52324, in 2.289s\n",
      "[1192/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.46000, val loss: 0.52324, in 2.165s\n",
      "[1193/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45994, val loss: 0.52322, in 2.008s\n",
      "[1194/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45989, val loss: 0.52321, in 1.847s\n",
      "[1195/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45983, val loss: 0.52319, in 2.373s\n",
      "[1196/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45977, val loss: 0.52318, in 2.147s\n",
      "[1197/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45969, val loss: 0.52313, in 2.294s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1198/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45963, val loss: 0.52313, in 2.134s\n",
      "[1199/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45959, val loss: 0.52312, in 2.159s\n",
      "[1200/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.45953, val loss: 0.52310, in 2.222s\n",
      "[1201/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45947, val loss: 0.52309, in 2.133s\n",
      "[1202/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45941, val loss: 0.52307, in 2.198s\n",
      "[1203/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45936, val loss: 0.52305, in 1.914s\n",
      "[1204/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45930, val loss: 0.52305, in 2.381s\n",
      "[1205/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45924, val loss: 0.52303, in 2.150s\n",
      "[1206/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45919, val loss: 0.52302, in 1.937s\n",
      "[1207/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45913, val loss: 0.52300, in 2.521s\n",
      "[1208/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45908, val loss: 0.52300, in 2.028s\n",
      "[1209/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45902, val loss: 0.52300, in 1.977s\n",
      "[1210/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45897, val loss: 0.52298, in 1.963s\n",
      "[1211/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45892, val loss: 0.52297, in 2.129s\n",
      "[1212/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45886, val loss: 0.52295, in 2.740s\n",
      "[1213/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45880, val loss: 0.52295, in 2.068s\n",
      "[1214/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45874, val loss: 0.52293, in 2.374s\n",
      "[1215/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45869, val loss: 0.52293, in 2.016s\n",
      "[1216/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45864, val loss: 0.52293, in 2.304s\n",
      "[1217/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45858, val loss: 0.52292, in 2.271s\n",
      "[1218/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45852, val loss: 0.52289, in 2.139s\n",
      "[1219/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45845, val loss: 0.52287, in 2.101s\n",
      "[1220/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45838, val loss: 0.52285, in 1.992s\n",
      "[1221/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45833, val loss: 0.52284, in 1.878s\n",
      "[1222/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45827, val loss: 0.52281, in 2.269s\n",
      "[1223/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45822, val loss: 0.52280, in 2.058s\n",
      "[1224/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45816, val loss: 0.52279, in 2.267s\n",
      "[1225/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45811, val loss: 0.52278, in 2.063s\n",
      "[1226/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45805, val loss: 0.52275, in 2.063s\n",
      "[1227/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45801, val loss: 0.52274, in 2.112s\n",
      "[1228/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45795, val loss: 0.52272, in 2.406s\n",
      "[1229/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45789, val loss: 0.52270, in 2.268s\n",
      "[1230/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45784, val loss: 0.52269, in 2.199s\n",
      "[1231/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.45778, val loss: 0.52268, in 2.184s\n",
      "[1232/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45773, val loss: 0.52267, in 2.105s\n",
      "[1233/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45767, val loss: 0.52265, in 2.027s\n",
      "[1234/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45764, val loss: 0.52265, in 1.786s\n",
      "[1235/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45759, val loss: 0.52264, in 2.039s\n",
      "[1236/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45753, val loss: 0.52262, in 2.109s\n",
      "[1237/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45746, val loss: 0.52260, in 2.325s\n",
      "[1238/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45742, val loss: 0.52259, in 1.877s\n",
      "[1239/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45735, val loss: 0.52256, in 2.425s\n",
      "[1240/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45730, val loss: 0.52254, in 2.336s\n",
      "[1241/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45725, val loss: 0.52253, in 1.875s\n",
      "[1242/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45720, val loss: 0.52253, in 2.240s\n",
      "[1243/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45715, val loss: 0.52252, in 2.021s\n",
      "[1244/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.45709, val loss: 0.52252, in 1.861s\n",
      "[1245/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45704, val loss: 0.52252, in 2.051s\n",
      "[1246/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.45699, val loss: 0.52250, in 2.234s\n",
      "[1247/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45693, val loss: 0.52250, in 2.177s\n",
      "[1248/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45687, val loss: 0.52248, in 2.061s\n",
      "[1249/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45681, val loss: 0.52246, in 1.970s\n",
      "[1250/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45676, val loss: 0.52245, in 1.956s\n",
      "[1251/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45669, val loss: 0.52242, in 2.217s\n",
      "[1252/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45664, val loss: 0.52241, in 2.209s\n",
      "[1253/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45659, val loss: 0.52239, in 2.246s\n",
      "[1254/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45654, val loss: 0.52239, in 2.271s\n",
      "[1255/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.45649, val loss: 0.52237, in 2.890s\n",
      "[1256/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45643, val loss: 0.52235, in 2.232s\n",
      "[1257/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45638, val loss: 0.52235, in 2.069s\n",
      "[1258/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45631, val loss: 0.52234, in 2.237s\n",
      "[1259/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45627, val loss: 0.52234, in 2.008s\n",
      "[1260/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45621, val loss: 0.52232, in 2.267s\n",
      "[1261/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45616, val loss: 0.52230, in 1.973s\n",
      "[1262/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45610, val loss: 0.52229, in 3.013s\n",
      "[1263/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45603, val loss: 0.52226, in 2.348s\n",
      "[1264/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45597, val loss: 0.52223, in 2.474s\n",
      "[1265/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45591, val loss: 0.52222, in 2.724s\n",
      "[1266/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45583, val loss: 0.52219, in 2.787s\n",
      "[1267/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45576, val loss: 0.52216, in 3.002s\n",
      "[1268/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45569, val loss: 0.52214, in 2.477s\n",
      "[1269/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45565, val loss: 0.52212, in 2.180s\n",
      "[1270/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45559, val loss: 0.52209, in 2.013s\n",
      "[1271/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45553, val loss: 0.52207, in 2.190s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1272/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45547, val loss: 0.52206, in 2.209s\n",
      "[1273/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45540, val loss: 0.52204, in 2.030s\n",
      "[1274/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45535, val loss: 0.52201, in 2.136s\n",
      "[1275/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45529, val loss: 0.52198, in 2.314s\n",
      "[1276/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45525, val loss: 0.52196, in 2.282s\n",
      "[1277/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.45519, val loss: 0.52195, in 2.089s\n",
      "[1278/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45513, val loss: 0.52194, in 2.480s\n",
      "[1279/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45508, val loss: 0.52192, in 2.087s\n",
      "[1280/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45501, val loss: 0.52189, in 2.119s\n",
      "[1281/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45495, val loss: 0.52187, in 2.144s\n",
      "[1282/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45491, val loss: 0.52186, in 2.192s\n",
      "[1283/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45485, val loss: 0.52185, in 2.103s\n",
      "[1284/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45480, val loss: 0.52184, in 2.182s\n",
      "[1285/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45473, val loss: 0.52182, in 2.228s\n",
      "[1286/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45468, val loss: 0.52181, in 2.113s\n",
      "[1287/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45463, val loss: 0.52180, in 2.089s\n",
      "[1288/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.45458, val loss: 0.52179, in 1.993s\n",
      "[1289/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45453, val loss: 0.52178, in 2.053s\n",
      "[1290/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45447, val loss: 0.52175, in 1.948s\n",
      "[1291/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45441, val loss: 0.52172, in 2.293s\n",
      "[1292/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45435, val loss: 0.52171, in 2.312s\n",
      "[1293/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45428, val loss: 0.52168, in 2.098s\n",
      "[1294/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45422, val loss: 0.52167, in 2.342s\n",
      "[1295/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45416, val loss: 0.52164, in 2.376s\n",
      "[1296/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45411, val loss: 0.52162, in 2.325s\n",
      "[1297/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45407, val loss: 0.52161, in 1.974s\n",
      "[1298/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45401, val loss: 0.52160, in 2.122s\n",
      "[1299/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45395, val loss: 0.52160, in 2.228s\n",
      "[1300/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45391, val loss: 0.52158, in 2.215s\n",
      "[1301/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45386, val loss: 0.52157, in 2.198s\n",
      "[1302/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45379, val loss: 0.52152, in 2.243s\n",
      "[1303/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45373, val loss: 0.52153, in 2.671s\n",
      "[1304/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45368, val loss: 0.52150, in 2.224s\n",
      "[1305/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.45362, val loss: 0.52148, in 2.276s\n",
      "[1306/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45357, val loss: 0.52147, in 2.241s\n",
      "[1307/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45352, val loss: 0.52145, in 2.433s\n",
      "[1308/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45347, val loss: 0.52145, in 2.125s\n",
      "[1309/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45343, val loss: 0.52145, in 2.012s\n",
      "[1310/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45339, val loss: 0.52143, in 2.140s\n",
      "[1311/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45334, val loss: 0.52143, in 2.819s\n",
      "[1312/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45329, val loss: 0.52142, in 2.310s\n",
      "[1313/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45323, val loss: 0.52140, in 2.387s\n",
      "[1314/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45318, val loss: 0.52138, in 2.432s\n",
      "[1315/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45312, val loss: 0.52137, in 2.045s\n",
      "[1316/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45306, val loss: 0.52135, in 2.382s\n",
      "[1317/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.45301, val loss: 0.52134, in 2.151s\n",
      "[1318/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45295, val loss: 0.52131, in 2.216s\n",
      "[1319/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.45290, val loss: 0.52130, in 2.194s\n",
      "[1320/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45285, val loss: 0.52130, in 1.806s\n",
      "[1321/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45280, val loss: 0.52129, in 1.990s\n",
      "[1322/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45275, val loss: 0.52129, in 1.988s\n",
      "[1323/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45270, val loss: 0.52128, in 2.109s\n",
      "[1324/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45264, val loss: 0.52125, in 2.549s\n",
      "[1325/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45258, val loss: 0.52125, in 2.211s\n",
      "[1326/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45252, val loss: 0.52124, in 2.460s\n",
      "[1327/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45248, val loss: 0.52123, in 2.126s\n",
      "[1328/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45244, val loss: 0.52121, in 1.954s\n",
      "[1329/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45239, val loss: 0.52121, in 2.055s\n",
      "[1330/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45233, val loss: 0.52119, in 2.385s\n",
      "[1331/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45228, val loss: 0.52118, in 2.002s\n",
      "[1332/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.45222, val loss: 0.52116, in 2.177s\n",
      "[1333/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45217, val loss: 0.52115, in 2.010s\n",
      "[1334/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45212, val loss: 0.52114, in 2.142s\n",
      "[1335/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45207, val loss: 0.52114, in 2.574s\n",
      "[1336/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45202, val loss: 0.52113, in 4.329s\n",
      "[1337/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45198, val loss: 0.52112, in 2.162s\n",
      "[1338/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45193, val loss: 0.52111, in 2.741s\n",
      "[1339/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45188, val loss: 0.52110, in 1.927s\n",
      "[1340/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45183, val loss: 0.52108, in 2.204s\n",
      "[1341/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45176, val loss: 0.52106, in 2.714s\n",
      "[1342/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45170, val loss: 0.52104, in 1.994s\n",
      "[1343/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45165, val loss: 0.52104, in 2.006s\n",
      "[1344/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45159, val loss: 0.52103, in 2.196s\n",
      "[1345/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45152, val loss: 0.52101, in 2.446s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1346/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45147, val loss: 0.52101, in 2.248s\n",
      "[1347/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45142, val loss: 0.52100, in 1.916s\n",
      "[1348/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45137, val loss: 0.52099, in 2.197s\n",
      "[1349/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.45133, val loss: 0.52099, in 2.142s\n",
      "[1350/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45126, val loss: 0.52097, in 2.413s\n",
      "[1351/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45121, val loss: 0.52096, in 2.145s\n",
      "[1352/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45115, val loss: 0.52094, in 2.491s\n",
      "[1353/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45110, val loss: 0.52092, in 1.963s\n",
      "[1354/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45105, val loss: 0.52090, in 2.151s\n",
      "[1355/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45099, val loss: 0.52086, in 2.092s\n",
      "[1356/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45093, val loss: 0.52085, in 2.337s\n",
      "[1357/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45089, val loss: 0.52084, in 2.346s\n",
      "[1358/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.45083, val loss: 0.52082, in 2.379s\n",
      "[1359/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45078, val loss: 0.52082, in 1.699s\n",
      "[1360/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45073, val loss: 0.52080, in 2.197s\n",
      "[1361/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.45068, val loss: 0.52078, in 2.115s\n",
      "[1362/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45063, val loss: 0.52077, in 1.923s\n",
      "[1363/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45059, val loss: 0.52076, in 2.997s\n",
      "[1364/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45053, val loss: 0.52074, in 2.154s\n",
      "[1365/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45047, val loss: 0.52073, in 2.090s\n",
      "[1366/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45041, val loss: 0.52070, in 2.244s\n",
      "[1367/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.45036, val loss: 0.52069, in 1.935s\n",
      "[1368/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45031, val loss: 0.52067, in 2.099s\n",
      "[1369/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45024, val loss: 0.52064, in 2.676s\n",
      "[1370/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45019, val loss: 0.52063, in 2.569s\n",
      "[1371/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.45014, val loss: 0.52061, in 2.254s\n",
      "[1372/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.45010, val loss: 0.52060, in 2.379s\n",
      "[1373/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.45005, val loss: 0.52059, in 2.309s\n",
      "[1374/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44999, val loss: 0.52056, in 2.848s\n",
      "[1375/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.44994, val loss: 0.52055, in 3.321s\n",
      "[1376/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44989, val loss: 0.52055, in 2.758s\n",
      "[1377/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44985, val loss: 0.52054, in 2.381s\n",
      "[1378/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44980, val loss: 0.52053, in 2.159s\n",
      "[1379/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44976, val loss: 0.52052, in 1.970s\n",
      "[1380/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44970, val loss: 0.52051, in 2.134s\n",
      "[1381/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44964, val loss: 0.52049, in 2.271s\n",
      "[1382/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44958, val loss: 0.52047, in 2.472s\n",
      "[1383/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44952, val loss: 0.52046, in 2.095s\n",
      "[1384/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44947, val loss: 0.52044, in 2.126s\n",
      "[1385/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44942, val loss: 0.52044, in 2.281s\n",
      "[1386/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44938, val loss: 0.52043, in 2.288s\n",
      "[1387/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44933, val loss: 0.52043, in 2.625s\n",
      "[1388/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.44928, val loss: 0.52042, in 2.991s\n",
      "[1389/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44923, val loss: 0.52040, in 3.170s\n",
      "[1390/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44919, val loss: 0.52039, in 2.688s\n",
      "[1391/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44914, val loss: 0.52038, in 1.961s\n",
      "[1392/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44910, val loss: 0.52037, in 1.897s\n",
      "[1393/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44904, val loss: 0.52035, in 2.053s\n",
      "[1394/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.44900, val loss: 0.52035, in 1.952s\n",
      "[1395/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44894, val loss: 0.52033, in 2.038s\n",
      "[1396/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44889, val loss: 0.52031, in 2.051s\n",
      "[1397/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.44884, val loss: 0.52030, in 2.268s\n",
      "[1398/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44878, val loss: 0.52028, in 2.337s\n",
      "[1399/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44874, val loss: 0.52029, in 2.057s\n",
      "[1400/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44869, val loss: 0.52028, in 2.020s\n",
      "[1401/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44863, val loss: 0.52029, in 2.114s\n",
      "[1402/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44858, val loss: 0.52027, in 2.007s\n",
      "[1403/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44852, val loss: 0.52025, in 2.160s\n",
      "[1404/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.44848, val loss: 0.52024, in 2.024s\n",
      "[1405/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.44843, val loss: 0.52022, in 2.125s\n",
      "[1406/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44838, val loss: 0.52021, in 2.066s\n",
      "[1407/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44833, val loss: 0.52019, in 2.156s\n",
      "[1408/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44828, val loss: 0.52018, in 2.062s\n",
      "[1409/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44824, val loss: 0.52018, in 1.894s\n",
      "[1410/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44819, val loss: 0.52016, in 2.375s\n",
      "[1411/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44815, val loss: 0.52015, in 2.390s\n",
      "[1412/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44809, val loss: 0.52016, in 2.758s\n",
      "[1413/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44804, val loss: 0.52015, in 4.841s\n",
      "[1414/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44799, val loss: 0.52013, in 2.557s\n",
      "[1415/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44793, val loss: 0.52012, in 1.974s\n",
      "[1416/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.44786, val loss: 0.52009, in 2.113s\n",
      "[1417/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44782, val loss: 0.52007, in 1.883s\n",
      "[1418/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44774, val loss: 0.52003, in 2.441s\n",
      "[1419/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44770, val loss: 0.52003, in 2.064s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1420/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44764, val loss: 0.52001, in 2.332s\n",
      "[1421/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44759, val loss: 0.52000, in 2.095s\n",
      "[1422/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44754, val loss: 0.51999, in 1.927s\n",
      "[1423/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44749, val loss: 0.51998, in 2.037s\n",
      "[1424/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44745, val loss: 0.51997, in 2.112s\n",
      "[1425/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44739, val loss: 0.51995, in 2.242s\n",
      "[1426/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.44734, val loss: 0.51994, in 2.025s\n",
      "[1427/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44729, val loss: 0.51992, in 1.916s\n",
      "[1428/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44722, val loss: 0.51990, in 2.666s\n",
      "[1429/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44718, val loss: 0.51990, in 2.619s\n",
      "[1430/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44713, val loss: 0.51988, in 2.300s\n",
      "[1431/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44709, val loss: 0.51988, in 1.976s\n",
      "[1432/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44703, val loss: 0.51986, in 2.113s\n",
      "[1433/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44698, val loss: 0.51985, in 2.380s\n",
      "[1434/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44694, val loss: 0.51984, in 3.699s\n",
      "[1435/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44689, val loss: 0.51983, in 2.237s\n",
      "[1436/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44685, val loss: 0.51982, in 2.125s\n",
      "[1437/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44681, val loss: 0.51981, in 2.000s\n",
      "[1438/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44676, val loss: 0.51980, in 2.120s\n",
      "[1439/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44671, val loss: 0.51980, in 2.203s\n",
      "[1440/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44666, val loss: 0.51980, in 2.021s\n",
      "[1441/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44661, val loss: 0.51978, in 2.309s\n",
      "[1442/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44655, val loss: 0.51975, in 2.170s\n",
      "[1443/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.44650, val loss: 0.51974, in 1.969s\n",
      "[1444/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44644, val loss: 0.51972, in 2.022s\n",
      "[1445/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44640, val loss: 0.51972, in 2.209s\n",
      "[1446/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44634, val loss: 0.51970, in 2.072s\n",
      "[1447/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44630, val loss: 0.51968, in 1.855s\n",
      "[1448/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.44624, val loss: 0.51967, in 2.181s\n",
      "[1449/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44618, val loss: 0.51964, in 2.172s\n",
      "[1450/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44614, val loss: 0.51963, in 1.985s\n",
      "[1451/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44610, val loss: 0.51963, in 2.238s\n",
      "[1452/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44604, val loss: 0.51960, in 2.098s\n",
      "[1453/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44599, val loss: 0.51958, in 2.225s\n",
      "[1454/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44594, val loss: 0.51957, in 2.375s\n",
      "[1455/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44589, val loss: 0.51956, in 3.795s\n",
      "[1456/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44585, val loss: 0.51956, in 2.056s\n",
      "[1457/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44581, val loss: 0.51956, in 1.979s\n",
      "[1458/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44576, val loss: 0.51954, in 2.447s\n",
      "[1459/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44571, val loss: 0.51954, in 2.209s\n",
      "[1460/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44566, val loss: 0.51953, in 2.936s\n",
      "[1461/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44561, val loss: 0.51951, in 2.772s\n",
      "[1462/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44556, val loss: 0.51951, in 2.819s\n",
      "[1463/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44552, val loss: 0.51950, in 2.542s\n",
      "[1464/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.44546, val loss: 0.51949, in 2.546s\n",
      "[1465/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44542, val loss: 0.51948, in 2.204s\n",
      "[1466/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44536, val loss: 0.51946, in 2.757s\n",
      "[1467/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44531, val loss: 0.51945, in 2.166s\n",
      "[1468/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.44526, val loss: 0.51944, in 3.758s\n",
      "[1469/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.44522, val loss: 0.51942, in 2.649s\n",
      "[1470/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44517, val loss: 0.51940, in 2.821s\n",
      "[1471/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.44512, val loss: 0.51940, in 3.022s\n",
      "[1472/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44509, val loss: 0.51940, in 3.728s\n",
      "[1473/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.44504, val loss: 0.51937, in 3.302s\n",
      "[1474/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44500, val loss: 0.51937, in 2.561s\n",
      "[1475/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44496, val loss: 0.51937, in 2.358s\n",
      "[1476/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44491, val loss: 0.51937, in 2.348s\n",
      "[1477/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44487, val loss: 0.51935, in 1.945s\n",
      "[1478/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44483, val loss: 0.51935, in 1.954s\n",
      "[1479/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.44479, val loss: 0.51935, in 1.925s\n",
      "[1480/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44473, val loss: 0.51933, in 3.203s\n",
      "[1481/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44469, val loss: 0.51931, in 2.173s\n",
      "[1482/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44464, val loss: 0.51930, in 2.201s\n",
      "[1483/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44460, val loss: 0.51930, in 2.028s\n",
      "[1484/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44455, val loss: 0.51929, in 2.502s\n",
      "[1485/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44449, val loss: 0.51928, in 2.531s\n",
      "[1486/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44443, val loss: 0.51926, in 3.929s\n",
      "[1487/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44438, val loss: 0.51925, in 3.547s\n",
      "[1488/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44434, val loss: 0.51924, in 2.958s\n",
      "[1489/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44428, val loss: 0.51924, in 2.852s\n",
      "[1490/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44422, val loss: 0.51921, in 2.224s\n",
      "[1491/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44416, val loss: 0.51919, in 2.945s\n",
      "[1492/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44411, val loss: 0.51919, in 2.130s\n",
      "[1493/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44407, val loss: 0.51919, in 2.039s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1494/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.44402, val loss: 0.51919, in 2.248s\n",
      "[1495/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44398, val loss: 0.51919, in 2.053s\n",
      "[1496/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.44394, val loss: 0.51918, in 2.937s\n",
      "[1497/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44390, val loss: 0.51917, in 1.970s\n",
      "[1498/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44385, val loss: 0.51916, in 2.603s\n",
      "[1499/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44379, val loss: 0.51914, in 2.518s\n",
      "[1500/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44374, val loss: 0.51912, in 2.205s\n",
      "[1501/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44369, val loss: 0.51911, in 3.324s\n",
      "[1502/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44364, val loss: 0.51910, in 2.298s\n",
      "[1503/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44358, val loss: 0.51909, in 2.523s\n",
      "[1504/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44352, val loss: 0.51907, in 3.420s\n",
      "[1505/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44347, val loss: 0.51907, in 2.364s\n",
      "[1506/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.44343, val loss: 0.51907, in 2.642s\n",
      "[1507/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44337, val loss: 0.51905, in 2.944s\n",
      "[1508/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44331, val loss: 0.51903, in 2.925s\n",
      "[1509/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44325, val loss: 0.51902, in 2.219s\n",
      "[1510/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.44320, val loss: 0.51900, in 2.715s\n",
      "[1511/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44314, val loss: 0.51899, in 2.741s\n",
      "[1512/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44310, val loss: 0.51899, in 2.803s\n",
      "[1513/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44304, val loss: 0.51898, in 2.801s\n",
      "[1514/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44300, val loss: 0.51896, in 3.494s\n",
      "[1515/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44296, val loss: 0.51896, in 2.297s\n",
      "[1516/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44291, val loss: 0.51894, in 2.283s\n",
      "[1517/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44285, val loss: 0.51893, in 2.235s\n",
      "[1518/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44281, val loss: 0.51892, in 2.383s\n",
      "[1519/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44276, val loss: 0.51891, in 2.158s\n",
      "[1520/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44272, val loss: 0.51889, in 2.784s\n",
      "[1521/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44267, val loss: 0.51888, in 2.691s\n",
      "[1522/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44261, val loss: 0.51888, in 2.726s\n",
      "[1523/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44256, val loss: 0.51885, in 2.600s\n",
      "[1524/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44251, val loss: 0.51884, in 2.211s\n",
      "[1525/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44268, val loss: 0.51911, in 1.929s\n",
      "[1526/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.44241, val loss: 0.51884, in 2.261s\n",
      "[1527/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.44237, val loss: 0.51883, in 1.929s\n",
      "[1528/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44232, val loss: 0.51882, in 2.088s\n",
      "[1529/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.44227, val loss: 0.51881, in 2.139s\n",
      "[1530/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44223, val loss: 0.51881, in 1.823s\n",
      "[1531/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.44217, val loss: 0.51881, in 2.116s\n",
      "[1532/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44212, val loss: 0.51880, in 2.292s\n",
      "[1533/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44208, val loss: 0.51879, in 1.984s\n",
      "[1534/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44202, val loss: 0.51877, in 2.176s\n",
      "[1535/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44198, val loss: 0.51877, in 2.060s\n",
      "[1536/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.44192, val loss: 0.51874, in 1.914s\n",
      "[1537/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44187, val loss: 0.51872, in 2.090s\n",
      "[1538/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44182, val loss: 0.51871, in 2.074s\n",
      "[1539/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44177, val loss: 0.51870, in 1.935s\n",
      "[1540/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44172, val loss: 0.51869, in 2.030s\n",
      "[1541/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44167, val loss: 0.51867, in 2.265s\n",
      "[1542/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44161, val loss: 0.51866, in 2.326s\n",
      "[1543/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.44157, val loss: 0.51866, in 2.136s\n",
      "[1544/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44151, val loss: 0.51864, in 2.947s\n",
      "[1545/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44145, val loss: 0.51863, in 2.921s\n",
      "[1546/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44140, val loss: 0.51861, in 2.145s\n",
      "[1547/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44133, val loss: 0.51860, in 2.231s\n",
      "[1548/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44128, val loss: 0.51859, in 2.640s\n",
      "[1549/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44125, val loss: 0.51857, in 2.232s\n",
      "[1550/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.44121, val loss: 0.51857, in 2.108s\n",
      "[1551/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44116, val loss: 0.51857, in 2.030s\n",
      "[1552/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44111, val loss: 0.51856, in 2.095s\n",
      "[1553/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.44106, val loss: 0.51854, in 2.406s\n",
      "[1554/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44101, val loss: 0.51853, in 2.076s\n",
      "[1555/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44096, val loss: 0.51853, in 2.231s\n",
      "[1556/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.44092, val loss: 0.51852, in 2.189s\n",
      "[1557/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44087, val loss: 0.51851, in 1.934s\n",
      "[1558/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44082, val loss: 0.51850, in 1.834s\n",
      "[1559/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44077, val loss: 0.51849, in 2.022s\n",
      "[1560/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.44073, val loss: 0.51848, in 2.205s\n",
      "[1561/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.44069, val loss: 0.51848, in 2.815s\n",
      "[1562/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44064, val loss: 0.51846, in 2.757s\n",
      "[1563/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44059, val loss: 0.51846, in 2.802s\n",
      "[1564/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44054, val loss: 0.51846, in 4.693s\n",
      "[1565/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44049, val loss: 0.51845, in 2.041s\n",
      "[1566/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44045, val loss: 0.51844, in 3.026s\n",
      "[1567/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44040, val loss: 0.51843, in 2.134s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1568/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.44034, val loss: 0.51841, in 2.527s\n",
      "[1569/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.44030, val loss: 0.51841, in 2.257s\n",
      "[1570/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.44026, val loss: 0.51839, in 1.906s\n",
      "[1571/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44022, val loss: 0.51838, in 1.909s\n",
      "[1572/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.44017, val loss: 0.51838, in 2.136s\n",
      "[1573/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44012, val loss: 0.51836, in 2.132s\n",
      "[1574/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.44007, val loss: 0.51836, in 4.072s\n",
      "[1575/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.44004, val loss: 0.51835, in 2.235s\n",
      "[1576/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43999, val loss: 0.51834, in 2.271s\n",
      "[1577/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43994, val loss: 0.51832, in 2.915s\n",
      "[1578/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43989, val loss: 0.51830, in 3.542s\n",
      "[1579/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43983, val loss: 0.51830, in 2.918s\n",
      "[1580/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43978, val loss: 0.51829, in 2.947s\n",
      "[1581/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43974, val loss: 0.51829, in 1.932s\n",
      "[1582/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43970, val loss: 0.51829, in 2.331s\n",
      "[1583/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43965, val loss: 0.51828, in 2.054s\n",
      "[1584/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43960, val loss: 0.51826, in 1.945s\n",
      "[1585/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43956, val loss: 0.51825, in 2.030s\n",
      "[1586/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43953, val loss: 0.51824, in 2.173s\n",
      "[1587/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.43949, val loss: 0.51824, in 2.119s\n",
      "[1588/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43944, val loss: 0.51822, in 2.276s\n",
      "[1589/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43939, val loss: 0.51823, in 2.063s\n",
      "[1590/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43934, val loss: 0.51821, in 2.139s\n",
      "[1591/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43929, val loss: 0.51819, in 2.291s\n",
      "[1592/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43925, val loss: 0.51819, in 2.212s\n",
      "[1593/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43920, val loss: 0.51817, in 2.394s\n",
      "[1594/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43915, val loss: 0.51815, in 2.138s\n",
      "[1595/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43911, val loss: 0.51815, in 2.191s\n",
      "[1596/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43906, val loss: 0.51814, in 3.218s\n",
      "[1597/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.43900, val loss: 0.51812, in 3.751s\n",
      "[1598/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43896, val loss: 0.51812, in 3.979s\n",
      "[1599/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43892, val loss: 0.51811, in 2.885s\n",
      "[1600/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43892, val loss: 0.51819, in 2.372s\n",
      "[1601/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43886, val loss: 0.51818, in 2.189s\n",
      "[1602/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.43881, val loss: 0.51816, in 2.121s\n",
      "[1603/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43877, val loss: 0.51815, in 2.348s\n",
      "[1604/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43872, val loss: 0.51813, in 2.363s\n",
      "[1605/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43867, val loss: 0.51813, in 2.209s\n",
      "[1606/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.43862, val loss: 0.51812, in 2.189s\n",
      "[1607/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43857, val loss: 0.51811, in 2.601s\n",
      "[1608/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.43853, val loss: 0.51809, in 2.092s\n",
      "[1609/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43848, val loss: 0.51812, in 2.669s\n",
      "[1610/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43843, val loss: 0.51812, in 2.373s\n",
      "[1611/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43839, val loss: 0.51811, in 3.718s\n",
      "[1612/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43833, val loss: 0.51810, in 2.975s\n",
      "[1613/5000] 7 trees, 217 leaves (31 on avg), max depth = 20, train loss: 0.43829, val loss: 0.51810, in 1.997s\n",
      "[1614/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43824, val loss: 0.51809, in 2.314s\n",
      "[1615/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43820, val loss: 0.51808, in 4.012s\n",
      "[1616/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43815, val loss: 0.51808, in 2.989s\n",
      "[1617/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43810, val loss: 0.51807, in 2.449s\n",
      "[1618/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43806, val loss: 0.51807, in 2.230s\n",
      "[1619/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43799, val loss: 0.51806, in 2.484s\n",
      "[1620/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43794, val loss: 0.51805, in 1.996s\n",
      "[1621/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43790, val loss: 0.51805, in 1.918s\n",
      "[1622/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43785, val loss: 0.51805, in 2.069s\n",
      "[1623/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43782, val loss: 0.51804, in 2.047s\n",
      "[1624/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.43777, val loss: 0.51804, in 2.091s\n",
      "[1625/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43772, val loss: 0.51803, in 2.095s\n",
      "[1626/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43768, val loss: 0.51801, in 2.086s\n",
      "[1627/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43762, val loss: 0.51801, in 2.157s\n",
      "[1628/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43757, val loss: 0.51800, in 2.172s\n",
      "[1629/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43753, val loss: 0.51799, in 2.073s\n",
      "[1630/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43749, val loss: 0.51798, in 2.394s\n",
      "[1631/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.43745, val loss: 0.51797, in 2.004s\n",
      "[1632/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43740, val loss: 0.51797, in 1.867s\n",
      "[1633/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43735, val loss: 0.51796, in 1.960s\n",
      "[1634/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43732, val loss: 0.51796, in 2.945s\n",
      "[1635/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.43728, val loss: 0.51796, in 2.078s\n",
      "[1636/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43722, val loss: 0.51795, in 3.035s\n",
      "[1637/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43718, val loss: 0.51795, in 3.299s\n",
      "[1638/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43714, val loss: 0.51794, in 2.189s\n",
      "[1639/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43710, val loss: 0.51793, in 2.756s\n",
      "[1640/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43706, val loss: 0.51793, in 3.749s\n",
      "[1641/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43701, val loss: 0.51790, in 2.189s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1642/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.43696, val loss: 0.51789, in 2.451s\n",
      "[1643/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43690, val loss: 0.51788, in 2.432s\n",
      "[1644/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43686, val loss: 0.51787, in 2.496s\n",
      "[1645/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43683, val loss: 0.51787, in 3.795s\n",
      "[1646/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43679, val loss: 0.51786, in 2.634s\n",
      "[1647/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43675, val loss: 0.51785, in 1.876s\n",
      "[1648/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43671, val loss: 0.51785, in 2.249s\n",
      "[1649/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43666, val loss: 0.51784, in 2.413s\n",
      "[1650/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43660, val loss: 0.51782, in 3.083s\n",
      "[1651/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43655, val loss: 0.51780, in 2.350s\n",
      "[1652/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.43651, val loss: 0.51780, in 2.423s\n",
      "[1653/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43648, val loss: 0.51779, in 2.745s\n",
      "[1654/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43643, val loss: 0.51779, in 2.970s\n",
      "[1655/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43639, val loss: 0.51778, in 2.721s\n",
      "[1656/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43634, val loss: 0.51777, in 2.811s\n",
      "[1657/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43630, val loss: 0.51777, in 2.509s\n",
      "[1658/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43627, val loss: 0.51777, in 1.737s\n",
      "[1659/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43624, val loss: 0.51777, in 2.509s\n",
      "[1660/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43620, val loss: 0.51777, in 2.490s\n",
      "[1661/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43614, val loss: 0.51776, in 2.301s\n",
      "[1662/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43609, val loss: 0.51775, in 2.574s\n",
      "[1663/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43605, val loss: 0.51774, in 2.417s\n",
      "[1664/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43600, val loss: 0.51773, in 2.268s\n",
      "[1665/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43595, val loss: 0.51773, in 2.696s\n",
      "[1666/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43590, val loss: 0.51772, in 3.014s\n",
      "[1667/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43586, val loss: 0.51771, in 2.050s\n",
      "[1668/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43582, val loss: 0.51771, in 2.899s\n",
      "[1669/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43578, val loss: 0.51770, in 3.107s\n",
      "[1670/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43573, val loss: 0.51768, in 2.732s\n",
      "[1671/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43568, val loss: 0.51767, in 2.284s\n",
      "[1672/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43563, val loss: 0.51765, in 2.338s\n",
      "[1673/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43557, val loss: 0.51763, in 2.654s\n",
      "[1674/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43552, val loss: 0.51763, in 3.153s\n",
      "[1675/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43547, val loss: 0.51761, in 2.869s\n",
      "[1676/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43542, val loss: 0.51760, in 2.262s\n",
      "[1677/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43538, val loss: 0.51760, in 2.449s\n",
      "[1678/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43534, val loss: 0.51760, in 2.186s\n",
      "[1679/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43530, val loss: 0.51759, in 2.688s\n",
      "[1680/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43526, val loss: 0.51758, in 2.645s\n",
      "[1681/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43521, val loss: 0.51758, in 3.201s\n",
      "[1682/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43517, val loss: 0.51757, in 2.408s\n",
      "[1683/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43513, val loss: 0.51757, in 2.725s\n",
      "[1684/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43509, val loss: 0.51756, in 2.318s\n",
      "[1685/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43506, val loss: 0.51756, in 2.165s\n",
      "[1686/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43503, val loss: 0.51756, in 2.177s\n",
      "[1687/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43498, val loss: 0.51755, in 2.379s\n",
      "[1688/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43492, val loss: 0.51753, in 3.196s\n",
      "[1689/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43488, val loss: 0.51753, in 2.387s\n",
      "[1690/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.43483, val loss: 0.51752, in 2.369s\n",
      "[1691/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43478, val loss: 0.51752, in 3.258s\n",
      "[1692/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43474, val loss: 0.51750, in 2.535s\n",
      "[1693/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.43469, val loss: 0.51750, in 2.404s\n",
      "[1694/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43465, val loss: 0.51749, in 2.933s\n",
      "[1695/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43460, val loss: 0.51747, in 3.342s\n",
      "[1696/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43455, val loss: 0.51747, in 2.639s\n",
      "[1697/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.43450, val loss: 0.51746, in 2.627s\n",
      "[1698/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43445, val loss: 0.51746, in 2.596s\n",
      "[1699/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43441, val loss: 0.51746, in 2.379s\n",
      "[1700/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43436, val loss: 0.51746, in 2.328s\n",
      "[1701/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43432, val loss: 0.51745, in 2.173s\n",
      "[1702/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.43428, val loss: 0.51744, in 2.339s\n",
      "[1703/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43421, val loss: 0.51745, in 2.560s\n",
      "[1704/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43418, val loss: 0.51743, in 2.487s\n",
      "[1705/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43413, val loss: 0.51743, in 2.888s\n",
      "[1706/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43408, val loss: 0.51740, in 2.144s\n",
      "[1707/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43405, val loss: 0.51740, in 2.101s\n",
      "[1708/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43401, val loss: 0.51739, in 2.105s\n",
      "[1709/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43397, val loss: 0.51739, in 1.949s\n",
      "[1710/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43393, val loss: 0.51739, in 2.123s\n",
      "[1711/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43387, val loss: 0.51737, in 2.108s\n",
      "[1712/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43382, val loss: 0.51736, in 2.645s\n",
      "[1713/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43377, val loss: 0.51735, in 2.137s\n",
      "[1714/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43373, val loss: 0.51734, in 2.172s\n",
      "[1715/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43369, val loss: 0.51734, in 2.719s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1716/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43364, val loss: 0.51732, in 2.493s\n",
      "[1717/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43359, val loss: 0.51731, in 2.937s\n",
      "[1718/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43355, val loss: 0.51731, in 2.234s\n",
      "[1719/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43351, val loss: 0.51731, in 2.327s\n",
      "[1720/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43348, val loss: 0.51731, in 2.244s\n",
      "[1721/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43344, val loss: 0.51731, in 2.587s\n",
      "[1722/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43340, val loss: 0.51730, in 2.993s\n",
      "[1723/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43335, val loss: 0.51728, in 2.325s\n",
      "[1724/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43331, val loss: 0.51728, in 1.907s\n",
      "[1725/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43327, val loss: 0.51728, in 3.056s\n",
      "[1726/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43324, val loss: 0.51727, in 2.788s\n",
      "[1727/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43320, val loss: 0.51727, in 2.996s\n",
      "[1728/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43315, val loss: 0.51726, in 2.271s\n",
      "[1729/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43311, val loss: 0.51726, in 2.176s\n",
      "[1730/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43307, val loss: 0.51725, in 2.589s\n",
      "[1731/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43302, val loss: 0.51724, in 2.342s\n",
      "[1732/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43296, val loss: 0.51724, in 3.444s\n",
      "[1733/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43292, val loss: 0.51722, in 2.189s\n",
      "[1734/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43288, val loss: 0.51722, in 3.189s\n",
      "[1735/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43284, val loss: 0.51721, in 2.804s\n",
      "[1736/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43281, val loss: 0.51721, in 2.164s\n",
      "[1737/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43276, val loss: 0.51720, in 2.441s\n",
      "[1738/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43272, val loss: 0.51720, in 2.282s\n",
      "[1739/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.43267, val loss: 0.51719, in 2.809s\n",
      "[1740/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.43263, val loss: 0.51718, in 2.734s\n",
      "[1741/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43259, val loss: 0.51717, in 2.576s\n",
      "[1742/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43254, val loss: 0.51717, in 2.458s\n",
      "[1743/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43248, val loss: 0.51716, in 2.394s\n",
      "[1744/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.43245, val loss: 0.51715, in 3.038s\n",
      "[1745/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43241, val loss: 0.51714, in 2.109s\n",
      "[1746/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43237, val loss: 0.51715, in 2.211s\n",
      "[1747/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43232, val loss: 0.51714, in 2.146s\n",
      "[1748/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43228, val loss: 0.51713, in 2.807s\n",
      "[1749/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43224, val loss: 0.51712, in 3.096s\n",
      "[1750/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43220, val loss: 0.51710, in 2.093s\n",
      "[1751/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43215, val loss: 0.51709, in 2.103s\n",
      "[1752/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43211, val loss: 0.51709, in 2.510s\n",
      "[1753/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43206, val loss: 0.51708, in 2.583s\n",
      "[1754/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43202, val loss: 0.51706, in 2.449s\n",
      "[1755/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43198, val loss: 0.51707, in 2.796s\n",
      "[1756/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43194, val loss: 0.51706, in 3.074s\n",
      "[1757/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.43190, val loss: 0.51706, in 2.198s\n",
      "[1758/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43186, val loss: 0.51705, in 2.372s\n",
      "[1759/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43182, val loss: 0.51706, in 2.243s\n",
      "[1760/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43178, val loss: 0.51705, in 1.881s\n",
      "[1761/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43175, val loss: 0.51705, in 2.552s\n",
      "[1762/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.43169, val loss: 0.51703, in 3.096s\n",
      "[1763/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43165, val loss: 0.51703, in 2.648s\n",
      "[1764/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43161, val loss: 0.51702, in 2.134s\n",
      "[1765/5000] 7 trees, 217 leaves (31 on avg), max depth = 11, train loss: 0.43156, val loss: 0.51702, in 2.302s\n",
      "[1766/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43152, val loss: 0.51700, in 2.295s\n",
      "[1767/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43148, val loss: 0.51700, in 2.402s\n",
      "[1768/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43143, val loss: 0.51699, in 3.235s\n",
      "[1769/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43139, val loss: 0.51697, in 2.918s\n",
      "[1770/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43134, val loss: 0.51698, in 3.695s\n",
      "[1771/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43128, val loss: 0.51697, in 2.401s\n",
      "[1772/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43123, val loss: 0.51696, in 2.254s\n",
      "[1773/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43118, val loss: 0.51696, in 2.124s\n",
      "[1774/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43115, val loss: 0.51696, in 2.225s\n",
      "[1775/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43111, val loss: 0.51695, in 2.201s\n",
      "[1776/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43107, val loss: 0.51695, in 2.086s\n",
      "[1777/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43103, val loss: 0.51694, in 2.528s\n",
      "[1778/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43099, val loss: 0.51692, in 3.273s\n",
      "[1779/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.43095, val loss: 0.51693, in 2.284s\n",
      "[1780/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43092, val loss: 0.51693, in 2.753s\n",
      "[1781/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43087, val loss: 0.51692, in 2.532s\n",
      "[1782/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43083, val loss: 0.51691, in 4.102s\n",
      "[1783/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43078, val loss: 0.51690, in 3.999s\n",
      "[1784/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43073, val loss: 0.51689, in 2.693s\n",
      "[1785/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43069, val loss: 0.51689, in 7.959s\n",
      "[1786/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43065, val loss: 0.51689, in 5.193s\n",
      "[1787/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43061, val loss: 0.51688, in 3.397s\n",
      "[1788/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.43058, val loss: 0.51688, in 2.894s\n",
      "[1789/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43053, val loss: 0.51688, in 2.502s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1790/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.43049, val loss: 0.51688, in 2.237s\n",
      "[1791/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43044, val loss: 0.51687, in 2.429s\n",
      "[1792/5000] 7 trees, 217 leaves (31 on avg), max depth = 21, train loss: 0.43040, val loss: 0.51686, in 2.734s\n",
      "[1793/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43036, val loss: 0.51685, in 2.381s\n",
      "[1794/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43031, val loss: 0.51684, in 2.294s\n",
      "[1795/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43027, val loss: 0.51684, in 2.432s\n",
      "[1796/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.43024, val loss: 0.51683, in 2.236s\n",
      "[1797/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.43019, val loss: 0.51682, in 3.255s\n",
      "[1798/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.43015, val loss: 0.51681, in 3.115s\n",
      "[1799/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43011, val loss: 0.51680, in 2.206s\n",
      "[1800/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.43007, val loss: 0.51679, in 2.138s\n",
      "[1801/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.43002, val loss: 0.51679, in 2.335s\n",
      "[1802/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42998, val loss: 0.51678, in 2.534s\n",
      "[1803/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.42993, val loss: 0.51677, in 2.581s\n",
      "[1804/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.42989, val loss: 0.51677, in 2.903s\n",
      "[1805/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.42985, val loss: 0.51676, in 5.750s\n",
      "[1806/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.42982, val loss: 0.51675, in 7.616s\n",
      "[1807/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.42978, val loss: 0.51675, in 2.454s\n",
      "[1808/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.42974, val loss: 0.51675, in 4.421s\n",
      "[1809/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42970, val loss: 0.51675, in 2.276s\n",
      "[1810/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42967, val loss: 0.51674, in 2.166s\n",
      "[1811/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42963, val loss: 0.51674, in 1.986s\n",
      "[1812/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.42960, val loss: 0.51674, in 2.805s\n",
      "[1813/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.42955, val loss: 0.51673, in 3.613s\n",
      "[1814/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42951, val loss: 0.51673, in 3.589s\n",
      "[1815/5000] 7 trees, 217 leaves (31 on avg), max depth = 19, train loss: 0.42948, val loss: 0.51673, in 2.813s\n",
      "[1816/5000] 7 trees, 217 leaves (31 on avg), max depth = 18, train loss: 0.42944, val loss: 0.51671, in 2.226s\n",
      "[1817/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42940, val loss: 0.51671, in 2.499s\n",
      "[1818/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42936, val loss: 0.51669, in 2.420s\n",
      "[1819/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.42932, val loss: 0.51668, in 2.851s\n",
      "[1820/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42927, val loss: 0.51667, in 2.267s\n",
      "[1821/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.42923, val loss: 0.51665, in 2.482s\n",
      "[1822/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42917, val loss: 0.51663, in 2.177s\n",
      "[1823/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.42913, val loss: 0.51662, in 2.250s\n",
      "[1824/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42909, val loss: 0.51661, in 2.434s\n",
      "[1825/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.42904, val loss: 0.51661, in 2.745s\n",
      "[1826/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.42900, val loss: 0.51662, in 3.797s\n",
      "[1827/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.42896, val loss: 0.51661, in 3.900s\n",
      "[1828/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.42891, val loss: 0.51661, in 2.557s\n",
      "[1829/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.42887, val loss: 0.51661, in 2.114s\n",
      "[1830/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42882, val loss: 0.51660, in 2.343s\n",
      "[1831/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42878, val loss: 0.51660, in 2.681s\n",
      "[1832/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42874, val loss: 0.51659, in 4.143s\n",
      "[1833/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.42869, val loss: 0.51658, in 2.496s\n",
      "[1834/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42866, val loss: 0.51657, in 2.139s\n",
      "[1835/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42862, val loss: 0.51656, in 2.892s\n",
      "[1836/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.42858, val loss: 0.51656, in 2.079s\n",
      "[1837/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42855, val loss: 0.51654, in 2.088s\n",
      "[1838/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42853, val loss: 0.51662, in 2.471s\n",
      "[1839/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42848, val loss: 0.51660, in 2.547s\n",
      "[1840/5000] 7 trees, 217 leaves (31 on avg), max depth = 15, train loss: 0.42844, val loss: 0.51660, in 2.518s\n",
      "[1841/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42841, val loss: 0.51660, in 2.137s\n",
      "[1842/5000] 7 trees, 217 leaves (31 on avg), max depth = 13, train loss: 0.42837, val loss: 0.51659, in 2.471s\n",
      "[1843/5000] 7 trees, 217 leaves (31 on avg), max depth = 12, train loss: 0.42833, val loss: 0.51659, in 2.549s\n",
      "[1844/5000] 7 trees, 217 leaves (31 on avg), max depth = 17, train loss: 0.42829, val loss: 0.51659, in 2.844s\n",
      "[1845/5000] 7 trees, 217 leaves (31 on avg), max depth = 14, train loss: 0.42824, val loss: 0.51658, in 2.229s\n",
      "[1846/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42819, val loss: 0.51658, in 2.170s\n",
      "[1847/5000] 7 trees, 217 leaves (31 on avg), max depth = 16, train loss: 0.42815, val loss: 0.51658, in 2.657s\n",
      "Fit 12929 trees in 5263.198 s, (400799 total leaves)\n",
      "Time spent computing histograms: 2440.435s\n",
      "Time spent finding best splits:  153.307s\n",
      "Time spent applying splits:      185.687s\n",
      "Time spent predicting:           14.831s\n",
      "Training time: 5263.236773490906 seconds\n",
      "Inference time: 160.23435258865356 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "model = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.03,\n",
    "    max_iter=5000,\n",
    "    categorical_features=X_train.columns.isin(categorical_cols),\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "start_time_fit = time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time_fit = time()\n",
    "print(f\"Training time: {end_time_fit - start_time_fit} seconds\")\n",
    "\n",
    "start_time_pred = time()\n",
    "y_pred = model.predict(X_test)\n",
    "end_time_pred = time()\n",
    "\n",
    "print(f\"Inference time: {end_time_pred - start_time_pred} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "054dd075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.71      0.38      0.49       295\n",
      "           B       0.89      0.86      0.88     23795\n",
      "           C       0.82      0.82      0.82     69618\n",
      "           D       0.78      0.81      0.79     90575\n",
      "           E       0.71      0.67      0.69     37444\n",
      "           F       0.66      0.49      0.56      6286\n",
      "           G       0.81      0.71      0.76      1871\n",
      "\n",
      "    accuracy                           0.79    229884\n",
      "   macro avg       0.77      0.68      0.71    229884\n",
      "weighted avg       0.79      0.79      0.79    229884\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, normalize=\"true\", ax=ax)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
