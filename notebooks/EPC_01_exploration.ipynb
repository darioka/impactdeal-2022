{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b830dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/darioka/impactdeal-2022.git\n",
    "#%cd impactdeal-2022\n",
    "#!pip install -r requirements.txt\n",
    "#!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c6547",
   "metadata": {},
   "source": [
    "# Data Exploration - EPC Rating\n",
    "\n",
    "\n",
    "In this notebook you will explore a dataset with known EPC ratings from three major cities in the UK.\n",
    "The data has been downloaded, subsampled and pseudonimized from https://epc.opendatacommunities.org/.\n",
    "\n",
    "Remember that our final goal with this dataset will be to train a machine learning model that predicts the energy rating of a dwelling, based on the other features of this dataset. But for the moment, we just need to understand what information it contains and become confident with it.\n",
    "\n",
    "## Loading the dataset\n",
    "\n",
    "The dataset is **known_epc_ratings.csv.gz**. The format is CSV but it's compressed with gzip, as it contains quite a few lines. But no worries, pandas can detect compression and handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bda7d4",
   "metadata": {},
   "source": [
    "## First look at the dataset\n",
    "\n",
    "Here is where you get to know the dataset. In this section, try to give answers to very simple questions like:\n",
    "\n",
    "* How many rows/columns?\n",
    "* What are there data types?\n",
    "* What are the meaning of the columns?\n",
    "* Are data types consistent with column descriptions?\n",
    "* What is the column with the EPC rating? How many classes are there?\n",
    "\n",
    "In particular, make sure to check the column descriptions ([column_description.tsv](https://github.com/darioka/impactdeal-2022/blob/main/data/column_description.tsv)) and compare them with actual data! This kind of sanity checks are often very useful with real-world datasets.\n",
    "\n",
    "Also, be flexible! The dataset is big (many columns, many more rows) and it's not very easy to \"take a look at it\"... why don't you [sample](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) a hundred rows, export them to a standard [csv](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) and read them with your favorite Excel-like tool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa0b7d",
   "metadata": {},
   "source": [
    "Finally, let's create lists with the name of the columns, divided by their type. It will be useful later, when we will do different kinds of analyses depending on data types.\n",
    "\n",
    "For you convenience, lists have already been created and the next cell will import them. Notice that, besides numerical and categorical columns, we make two more groups:\n",
    "\n",
    "* **ids**: uniquely identify a single sample or a small set of them. No useful information can be inferred from them.\n",
    "\n",
    "* **dates**: cannot be treated naively as numbers nor as categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c017c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from impactdeal.config.column_names import TARGET, IDS, DATES, NUMERICAL, CATEGORICAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cb7cb",
   "metadata": {},
   "source": [
    "## Missing values\n",
    "\n",
    "It would be great if missing values were always clearly indicated as `np.nan`! Unfortunately, data collection is complex business and invalid data can be encoded in many more ways. For example, the people and the software that collected the data could have written `\"NULL\"` or `\"missing\"` to indicate an unknown value. This is one of the aspects of dealing with [data quality](https://en.wikipedia.org/wiki/Data_quality).\n",
    "\n",
    "Use the following cell to find missing values in the columns `ENERGY_TARIFF`, `FLOOR_LEVEL` and `GLAZED_TYPE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76243035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1db91",
   "metadata": {},
   "source": [
    "Now, if we want to count how many missing values are present in the dataset, we should replace the values you found with `np.nan`, so that all can be counted together.\n",
    "\n",
    "Let's write a function that:\n",
    "1. takes two inputs: a dataframe and the names of the columns to check,\n",
    "2. replace all values that we consider missing values with `np.nan`\n",
    "3. returns the new dataframe.\n",
    "\n",
    "Some hints:\n",
    "- in (2) we should include all the values found before, plus an additional pattern (it can be found in other columns): all values starting with `SAP05` or `sap05` are missing values too. \n",
    "- make the search case insensitive i.e. `hello` and `HELLO` are the same values,\n",
    "- you can `.copy()` the input dataframe to make sure to return a new independent copy of the dataframe\n",
    "- to iterate faster during development, try first with just one column or a few rows.\n",
    "\n",
    "Take your time, this is a hard task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6006d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_missing(df, columns):\n",
    "#     ...\n",
    "#     return new_df\n",
    "\n",
    "# new_df = normalize_missing(df, columns=CATEGORICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113db26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a possible solution (but try first to solve the problem by yourself)\n",
    "\n",
    "# from impactdeal.cleaning import normalize_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb865734",
   "metadata": {},
   "source": [
    "Now we are ready to check the completeness of the dataset. Let's print all relative frequencies of missing values for each column, ordered from the largest to the smallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372bde5",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "In the following section, we will try to answer some questions with the help of our dataset:\n",
    "\n",
    "1. What is the evolution in time of the number of EPC rating? Try to visualize the time series.\n",
    "\n",
    "2. Which city has more buildings in the lowest categories? Rank cities by the number of properties with EPC rating lower than E.\n",
    "\n",
    "3. What is the distribution of construction dates?\n",
    "\n",
    "4. How spread is the use of low energy lighting?\n",
    "\n",
    "5. Are there outliers in properties' total floor area? If yes, how should we treat them?\n",
    "\n",
    "6. There are multiple variables with information about the dimension of the property and multiple variables with information about the lighting. What are their correlations? What could we do here?\n",
    "\n",
    "\n",
    "Some hints:\n",
    "* Some of the questions are deliberately ambiguous, because business questions usually are.\n",
    "* For dates, take a look at `pandas` [to_datetime](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) and [datetime methods](https://pandas.pydata.org/docs/user_guide/timeseries.html#time-series-date-functionality).\n",
    "* `COSTRUCTION_AGE_BAND` needs some cleaning. If you are in a hurry, use the function `impactdeal.cleaning.clean_age_band`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
